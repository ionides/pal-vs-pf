@misc{gettingstartpomp,
    Author = {Aaron King},
    Date-Added = {2013-11-21 09:15:03 +0000},
    Date-Modified = {2013-11-21 09:26:00 +0000},
    Howpublished = {Getting Started with pomp: {\url{https://kingaa.github.io/pomp/vignettes/getting_started.html#Partially_observed_Markov_process_(POMP)_models}}},
    Lastchecked = {Nov 01, 2013},
    Month = {January},
    Url = {http://edition.cnn.com/2011/POLITICS/01/27/emanuel.ballot/},
    Urldate = {Jan 28, 2011},
    Year = {2024}}

@misc{CDC,
  Author = {CDC},
  Date-Added = {2013-11-21 09:15:03 +0000},
  Date-Modified = {2013-11-21 09:26:00 +0000},
  howpublished = {Available from: \url{http://www.cdc.gov/rotavirus/about/index.html}},
  Lastchecked = {Nov 01, 2013},
  Month = {January},
  Urldate = {Jan 28, 2024},
  Year = {2020}
}



@article{annurev:/content/journals/10.1146/annurev-control-042920-015119,
   author = "Wills, Adrian G. and Schön, Thomas B.",
   title = "Sequential {M}onte {C}arlo: A Unified Review", 
   journal= "Annual Review of Control, Robotics, and Autonomous Systems",
   year = "2023",
   volume = "6",
   number = "Volume 6, 2023",
   pages = "159-182",
   publisher = "Annual Reviews",
   type = "Journal Article",
   keywords = "state estimation",
   keywords = "sequential Monte Carlo",
   keywords = "particle filter",
   keywords = "nonlinear state-space model",
   keywords = "system identification",
   abstract = "Sequential Monte Carlo methods—also known as particle filters—offer approximate solutions to filtering problems for nonlinear state-space systems. These filtering problems are notoriously difficult to solve in general due to a lack of closed-form expressions and challenging expectation integrals. The essential idea behind particle filters is to employ Monte Carlo integration techniques in order to ameliorate both of these challenges. This article presents an intuitive introduction to the main particle filter ideas and then unifies three commonly employed particle filtering algorithms. This unified approach relies on a nonstandard presentation of the particle filter, which has the advantage of highlighting precisely where the differences between these algorithms stem from. Some relevant extensions and successful application domains of the particle filter are also presented.",
  }


@ARTICLE{Smith1992-st,
  title     = "Bayesian Statistics without Tears: A {Sampling-Resampling}
               Perspective",
  author    = "Smith, A F M and Gelfand, A E",
  abstract  = "[Even to the initiated, statistical calculations based on
               Bayes's Theorem can be daunting because of the numerical
               integrations required in all but the simplest applications.
               Moreover, from a teaching perspective, introductions to Bayesian
               statistics-if they are given at all-are circumscribed by these
               apparent calculational difficulties. Here we offer a
               straightforward sampling-resampling perspective on Bayesian
               inference, which has both pedagogic appeal and suggests easily
               implemented calculation strategies.]",
  journal   = "The American Statistician",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  46,
  number    =  2,
  pages     = "84--88",
  year      =  1992
}


@article{TSIR_package,
    author = {Becker, Alexander D. AND Grenfell, Bryan T.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {tsi{R}: {A}n {R} package for time-series Susceptible-Infected-Recovered models of epidemics},
    year = {2017},
    month = {09},
    volume = {12},
    pages = {1-10},
    abstract = {tsiR is an open source software package implemented in the R programming language designed to analyze infectious disease time-series data. The software extends a well-studied and widely-applied algorithm, the time-series Susceptible-Infected-Recovered (TSIR) model, to infer parameters from incidence data, such as contact seasonality, and to forward simulate the underlying mechanistic model. The tsiR package aggregates a number of different fitting features previously described in the literature in a user-friendly way, providing support for their broader adoption in infectious disease research. Also included in tsiR are a number of diagnostic tools to assess the fit of the TSIR model. This package should be useful for researchers analyzing incidence data for fully-immunizing infectious diseases.},
    number = {9},

}

@ARTICLE{TSIR1,
  title     = "Dynamics of Measles Epidemics: Estimating Scaling of
               Transmission Rates Using a Time Series {SIR} Model",
  author    = "Bj{\o}rnstad, Ottar N and Finkenst{\"a}dt, B{\"a}rbel F and
               Grenfell, Bryan T",
  abstract  = "[Before the development of mass-vaccination campaigns, measles
               exhibited persistent fluctuations (endemic dynamics) in large
               British cities, and recurrent outbreaks (episodic dynamics) in
               smaller communities. The critical community size separating the
               two regimes was ~300 000-500 000. We develop a model, the TSIR
               (Time-series Susceptible-Infected-Recovered) model, that can
               capture both endemic cycles and episodic outbreaks in measles.
               The model includes the stochasticity inherent in the disease
               transmission (giving rise to a negative binomial conditional
               distribution) and random immigration. It is thus a doubly
               stochastic model for disease dynamics. It further includes
               seasonality in the transmission rates. All parameters of the
               model are estimated on the basis of time series data on reported
               cases and reconstructed susceptible numbers from a set of cities
               in England and Wales in the prevaccination era (1944-1966). The
               60 cities analyzed span a size range from London (3.3$\times$
               106 inhabitants) to Teignmouth (10 500 inhabitants). The
               dynamics of all cities fit the model well. Transmission rates
               scale with community size, as expected from dynamics adhering
               closely to frequency dependent transmission (``true mass
               action''). These rates are further found to reveal strong
               seasonal variation, corresponding to high transmission during
               school terms and lower transmission during the school holidays.
               The basic reproductive ratio, R0, is found to be invariant
               across the observed range of host community size, and the mean
               proportion of susceptible individuals also appears to be
               constant. Through the epidemic cycle, the susceptible population
               is kept within a 3\% interval. The disease is, thus, efficient
               in ``regulating'' the susceptible population-even in small
               cities that undergo recurrent epidemics with frequent extinction
               of the disease agent. Recolonization is highly sensitive to the
               random immigration process. The initial phase of the epidemic is
               also stochastic (due to demographic stochasticity and random
               immigration). However, the epidemic is nearly ``deterministic''
               through most of the growth and decline phase.]",
  journal   = "Ecological Monographs",
  publisher = "Ecological Society of America",
  volume    =  72,
  number    =  2,
  pages     = "169--184",
  year      =  2002
}


@ARTICLE{Kitagawa1987-fr,
  title     = "{Non-Gaussian} State-Space Modeling of Nonstationary Time
               Series",
  author    = "Kitagawa, Genshiro",
  abstract  = "[A non-Gaussian state-space approach to the modeling of
               nonstationary time series is shown. The model is expressed in
               state-space form, where the system noise and the observational
               noise are not necessarily Gaussian. Recursive formulas of
               prediction, filtering, and smoothing for the state estimation
               and identification of the non-Gaussian state-space model are
               given. Also given is a numerical method based on piecewise
               linear approximation to the density functions for realizing
               these formulas. Significant merits of non-Gaussian modeling and
               the wide range of applicability of the method are illustrated by
               some numerical examples. A typical application of this
               non-Gaussian modeling is the smoothing of a time series that has
               mean value function with both abrupt and gradual changes. Simple
               Gaussian state-space modeling is not adequate for this
               situation. Here the model with small system noise variance
               cannot detect jump, whereas the one with large system noise
               variance yields unfavorable wiggle. To work out this problem
               within the ordinary linear Gaussian model framework,
               sophisticated treatment of outliers is required. But by the use
               of an appropriate non-Gaussian model for system noise, it is
               possible to reproduce both abrupt and gradual change of the mean
               without any special treatment. Nonstandard observations such as
               the ones distributed as non-Gaussian distribution can be easily
               treated by the direct modeling of an observational scheme.
               Smoothing of a transformed series such as a log periodogram can
               be treated by this method. Outliers in the observations can be
               treated as well by using heavy-tailed distribution for
               observational noise density. The algorithms herein can be easily
               extended to a wider class of models. As an example, the
               smoothing of nonhomogeneous binomial mean function is shown,
               where the observation is distributed according to a discrete
               random variable. Extension to a nonlinear system is also
               straightforward.]",
  journal   = "Journal of the American Statistical Association",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  82,
  number    =  400,
  pages     = "1032--1041",
  year      =  1987
}

@article{
daihai2,
author = {Daihai He  and Lixin Lin  and Yael Artzy-Randrup  and Haydar Demirhan  and Benjamin J. Cowling  and Lewi Stone },
title = {Resolving the enigma of {Iquitos} and {Manaus}: A modeling analysis of multiple {COVID-19} epidemic waves in two {Amazonian} cities},
journal = {Proceedings of the National Academy of Sciences},
volume = {120},
number = {10},
pages = {e2211422120},
year = {2023},
abstract = {The two nearby Amazonian cities of Iquitos and Manaus endured explosive COVID-19 epidemics and may well have suffered the world’s highest infection and death rates over 2020, the first year of the pandemic. State-of-the-art epidemiological and modeling studies estimated that the populations of both cities came close to attaining herd immunity (\&gt;70\% infected) at the termination of the first wave and were thus protected. This makes it difficult to explain the more deadly second wave of COVID-19 that struck again in Manaus just months later, simultaneous with the appearance of a new P.1 variant of concern, creating a catastrophe for the unprepared population. It was suggested that the second wave was driven by reinfections, but the episode has become controversial and an enigma in the history of the pandemic. We present a data-driven model of epidemic dynamics in Iquitos, which we also use to explain and model events in Manaus. By reverse engineering the multiple epidemic waves over 2 y in these two cities, the partially observed Markov process model inferred that the first wave left Manaus with a highly susceptible and vulnerable population (≈40\% infected) open to invasion by P.1, in contrast to Iquitos (≈72\% infected). The model reconstructed the full epidemic outbreak dynamics from mortality data by fitting a flexible time-varying reproductive number R0t while estimating reinfection and impulsive immune evasion. The approach is currently highly relevant given the lack of tools available to assess these factors as new SARS-CoV-2 virus variants appear with different degrees of immune evasion.}}



@article{gneiting2,
author = {Tilmann Gneiting and Adrian E Raftery},
title = {Strictly proper scoring rules, prediction, and estimation},
journal = {Journal of the American Statistical Association},
volume = {102},
number = {477},
pages = {359--378},
year = {2007},
publisher = {Taylor \& Francis}

}



@article{gneiting1,
    author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
    title = "{Probabilistic forecasts, calibration and sharpness}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {69},
    number = {2},
    pages = {243-268},
    year = {2007},
    month = {03},
    abstract = "{Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the US Pacific Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection.}"
}



@ARTICLE{Lambert2009-it,
  title    = "Early evidence for direct and indirect effects of the infant
              rotavirus vaccine program in {Queensland}",
  author   = "Lambert, Stephen B and Faux, Cassandra E and Hall, Lisa and
              Birrell, Frances A and Peterson, Karen V and Selvey, Christine E
              and Sloots, Theo P and Nissen, Michael D and Grimwood, Keith",
  abstract = "OBJECTIVE: To assess the impact of introducing a publicly funded
              infant rotavirus vaccination program on disease notifications and
              on laboratory testing and results. DESIGN AND SETTING:
              Retrospective analysis of routinely collected data (rotavirus
              notifications [2006-2008] and laboratory rotavirus testing data
              from Queensland Health laboratories [2000-2008]) to monitor
              rotavirus trends before and after the introduction of a publicly
              funded infant rotavirus vaccination program in Queensland in July
              2007. MAIN OUTCOME MEASURES: Age group-specific rotavirus
              notification trends; number of rotavirus tests performed and the
              proportion positive. RESULTS: In the less than 2 years age group,
              rotavirus notifications declined by 53\% (2007) and 65\% (2008);
              the number of laboratory tests performed declined by 3\% (2007)
              and 15\% (2008); and the proportion of tests positive declined by
              45\% (2007) and 43\% (2008) compared with data collected before
              introduction of the vaccination program. An indirect effect of
              infant vaccination was seen: notifications and the proportion of
              tests positive for rotavirus declined in older age groups as
              well. CONCLUSIONS: The publicly funded rotavirus vaccination
              program in Queensland is having an early impact, direct and
              indirect, on rotavirus disease as assessed using routinely
              collected data. Further observational studies are required to
              assess vaccine effectiveness. Parents and immunisation providers
              should ensure that all Australian children receive the
              recommended rotavirus vaccine doses in the required timeframe.",
  journal  = "Med J Aust",
  volume   =  191,
  number   =  3,
  pages    = "157--160",
  month    =  aug,
  year     =  2009,
  address  = "Australia",
  language = "en"
}


@article{pomppackagepaper,
 title={Statistical Inference for Partially Observed {M}arkov Processes via the {R} Package pomp},
 volume={69},
 abstract={Partially observed Markov process (POMP) models, also known as hidden Markov models or state space models, are ubiquitous tools for time series analysis. The R package pomp provides a very flexible framework for Monte Carlo statistical investigations using nonlinear, non-Gaussian POMP models. A range of modern statistical methods for POMP models have been implemented in this framework including sequential Monte Carlo, iterated filtering, particle Markov chain Monte Carlo, approximate Bayesian computation, maximum synthetic likelihood estimation, nonlinear forecasting, and trajectory matching. In this paper, we demonstrate the application of these methodologies using some simple toy problems. We also illustrate the specification of more complex POMP models, using a nonlinear epidemiological model with a discrete population, seasonality, and extra-demographic stochasticity. We discuss the specification of user-defined models and the development of additional methods within the programming environment provided by pomp.},
 number={12},
 journal={Journal of Statistical Software},
 author={King, Aaron A. and Nguyen, Dao and Ionides, Edward L.},
 year={2016},
 pages={1–43}
}

@ARTICLE{bayesiandoucet,
  title    = "On sequential {M}onte {C}arlo sampling methods for {B}ayesian filtering",
  author   = "Doucet, Arnaud and Godsill, Simon and Andrieu, Christophe",
  abstract = "In this article, we present an overview of methods for sequential
              simulation from posterior distributions. These methods are of
              particular interest in Bayesian filtering for discrete time
              dynamic models that are typically nonlinear and non-Gaussian. A
              general importance sampling framework is developed that unifies
              many of the methods which have been proposed over the last few
              decades in several different scientific disciplines. Novel
              extensions to the existing methods are also proposed. We show in
              particular how to incorporate local linearisation methods similar
              to those which have previously been employed in the deterministic
              filtering literature; these lead to very effective importance
              distributions. Furthermore we describe a method which uses
              Rao-Blackwellisation in order to take advantage of the analytic
              structure present in some important classes of state-space
              models. In a final section we develop algorithms for prediction,
              smoothing and evaluation of the likelihood in dynamic models.",
  journal  = "Statistics and Computing",
  volume   =  10,
  number   =  3,
  pages    = "197--208",
  month    =  jul,
  year     =  2000
}


@ARTICLE{geweke1989,
title = {Bayesian Inference in Econometric Models Using {M}onte {C}arlo Integration},
author = {Geweke, John},
year = {1989},
journal = {Econometrica},
volume = {57},
number = {6},
pages = {1317-39},
abstract = {Methods for the systematic application of Monte Carlo integration with importance sampling to Bayesian inference are developed. Conditions under which the numerical approximation converges almost surely to the true value with the number of Monte Carlo replications, and its numerical accuracy may be assessed reliably, are given. Importance sampling densities are derived from multivariate normal or student approximations to the posterior density. These densities are modified by automatic rescaling along each axis. The concept of relative numerical efficiency is introduced to evaluate the adequacy of a chosen importance sampling density. Applications in two illustrative models are presented. Copyright 1989 by The Econometric Society.}
}



@book{Doucet,
author="Doucet, Arnaud
and de Freitas, Nando
and Gordon, Neil",
title="Sequential {M}onte {C}arlo Methods in Practice",
year="2001",
publisher="Springer New York",
address="New York, NY",
abstract="Particle filtering in high dimensional state-spaces can be inefficient because a large number of samples is needed to represent the posterior. A standard technique to increase the efficiency of sampling techniques is to reduce the size of the state space by marginalizing out some of the variables analytically; this is called Rao-Blackwellisation (Casella and Robert 1996). Combining these two techniques results in Rao-Blackwellised particle filtering (RBPF) (Doucet 1998, Doucet, de Freitas, Murphy and Russell 2000). In this chapter, we explain RBPF, discuss when it can be used, and give a detailed example of its application to the problem of map learning for a mobile robot, which has a very large ({\textasciitilde} 2100) discrete state space."
}



@article{gridbasedfilter,
title = {Digital synthesis of non-linear filters},
journal = {Automatica},
volume = {7},
number = {3},
pages = {287-298},
year = {1971},
author = {R.S. Bucy and K.D. Senne},
abstract = {Practical implementation of discrete-time Bayesoptimal non-linear estimators has not received much attention, since the problems associated with storing probability densities and computing convolution integrals are formidable, and, hence, presumably prohibitive. However, the prevailing technique of designing non-linear estimators based upon Taylor series approximations frequently leads to undesirable, inaccurate or unstable, behavior. Thus there is considerable motivation for proceeding with the development of digital realizations of non-linear filters whose degree of accuracy is under the complete control of the computer program. In this paper techniques are proposed and discussed which solve the basic two subproblems associated with optimal discrete-time non-linear estimators: density storage and Bayes-law computation. For density storage a point mass representation on a floating rectangular grid of indices is proposed, while for the Bayes-law computation a simple and effective convolution summation involving an ellipsoid tracking technique to determine the important points to include in the summation is developed. Monte Carlo experiments with the proposed non-linear estimator reveal significant improvement in mean-square error behavior over some conventional approximation realizations. An example is given which illustrates the application of non-linear estimation to tracking and detection systems.
Résumé
La réalisation pratique des estimations non-linéaires, optimaux dans le sens de Bayes et à temps discret n'a pas beaucoup retenu l'attention, étant donné que les problèmes liés à la mémorisation des densités de probabilité et au calcul d'intégrales de convolution sont formidables et, par conséquent, probablement prohibitifs. Toutefois, la technique préponderante de calcul d'estimations non-linéaires basée sur l'approximation à l'aide de séries de Taylor conduit souvent à un comportement indésirable, c'est à dire imprécis ou instable. Il existe ainsi une motivation considérable à continuer le developpement des réalisations numériques de filtres non-linéaires dont le degré de précision se trouve placé sous la dependance totale du programme du calculateur. Dans le présent article, des techniques sont proposées et discutées pour la solution des deux sous-problèmes fondamentaux associés avec les estimations non-linéaires optimaux à temps discret: la mémorisation de la densité et le calcul selon la loi de Bayes. Pour la mémorisation de la densité, l'article propose une représentation ponctuelle des masses sur une grille rectangulaire flottante d'indices, alors qu'il developpe, pour le calcul selon la loi de Bayes, une sommation convolutive, simple et efficace, mettant en oeuvre une technique de poursuite ellipsoïdale pour determiner les points importants à inclure dans la sommation. Des experimentations Monte-Carlo avec l'estimation non-linéaire proposée font apparaître des améliorations sensibles dans le comportement de l'erreur quadratique moyenne par rapport à certaines réalisations conventionnelles de l'approximation. Un exemple illustre l'application de l'estimation non-linéaire à des systèmes de poursuite et de détection.
Zusammenfassung
Die praktische Verwirklichung von zeitdiskreten nichtlinearen im Bayesschen Sinne optimalen Schätzeinrichtungen hat nicht viel Aufmerksamkeit gefunden, weil die mit der Speicherung von Wahrscheinlichkeitsdichten und der Berechnung von Faltungsintegralen verknüpften Probleme furchtbar sind und sich daher vermutlich verbieten. Jedoch führt das maßgebende Verfahren des Entwurfes nichtlinearer Schätzeinrichtungen, das auf einer Taylorreihenentwicklung basiert, häufig zu unerwünschten, d.h. ungenauem oder unstabilem Verhalten. Also gibt es eine gewichtige Begründung für das Fortschreiten bei der Entwicklung digitaler Realisierungen nichtlinearer Filter, deren Genauigkeitsgrad der vollständigen Kontrolle des Rechenprogrammes unterliegt. In dieser Arbeit werden verfahren vorgestellt und diskutiert, die die zwei Hauptunterprobleme lösen, die mit optimalen zeitdiskreten nichtlinearen Schätzeinrichtungen verknüpft sind: Dichtespeicher und Berechnung des Bayesschen Gesetzes. Für die Dichtespeicher wird eine Punkt-Massendarstellung in einem rechtwinkligen Netz von Indizes vorgeschlagen, während für die Berechnung des Bayesschen Gesetzes eine einfache und wirkungsvolle Faltungssummation entwickelt wird, um die wichtigen Punkte zu bestimmen, die in die Summation eingehen. Monte-Carlo-Experimente mit der vorgeschlagenen nicht-linearen Schätzeinrichtung ezeigen wesentliche Verbesserungen im Verhalten des mittleren quadratischen Fehlers gegenüber einigen konventionellen Realisierungen mit Approximationen auf. Ein Beispiel wird gegeben, das die Anwendung nichtlinearer Schätzeinrichtungen auf angegebene spezielle Systeme illustriert.}
}

@article{gaussiansumfilter,
author = {Sorenson, H. W. and Alspach, D. L.},
title = {Recursive {B}ayesian estimation using {G}aussian sums},
year = {1971},
issue_date = {July, 1971},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {7},
number = {4},
abstract = {The Bayesian recursion relations which describe the behavior of the a posteriori probability density function of the state of a time-discrete stochastic system conditioned on available measurement data cannot generally be solved in closed-form when the system is either non-linear or nongaussian. In this paper a density approximation involving convex combinations of gaussian density functions is introduced and proposed as a meaningful way of circumventing the difficulties encountered in evaluating these relations and in using the resulting densities to determine specific estimation policies. It is seen that as the number of terms in the gaussian sum increases without bound, the approximation converges uniformly to any density function in a large class. Further, any finite sum is itself a valid density function unlike many other approximations that have been investigated. The problem of determining the a posteriori density and minimum variance estimates for linear systems with nongaussian noise is treated using the gaussian sum approximation. This problem is considered because it can be dealt with in a relatively straightforward manner using the approximation but still contains most of the difficulties that one encounters in considering non-linear systems since the a posteriori density is nongaussian. After discussing the general problem from the point-of-view of applying gaussian sums, a numerical example is presented in which the actual statistics of the a posteriori density are compared with the values predicted by the gaussian sum and by the Kalman filter approximations.},
journal = {Automatica},
month = {jul},
pages = {465–479},
numpages = {15}
}

@book{AndersonMoore1979,
  author    = {Brian D. O. Anderson and John B. Moore},
  title     = {Optimal Filtering},
  publisher = {Prentice-Hall},
  year      = {1979},
  address   = {Englewood Cliffs, NJ}
}


@ARTICLE{Schmidler2000-protein,
  title    = "Bayesian segmentation of protein secondary structure",
  author   = "Schmidler, S C and Liu, J S and Brutlag, D L",
  abstract = "We present a novel method for predicting the secondary structure
              of a protein from its amino acid sequence. Most existing methods
              predict each position in turn based on a local window of
              residues, sliding this window along the length of the sequence.
              In contrast, we develop a probabilistic model of protein
              sequence/structure relationships in terms of structural segments,
              and formulate secondary structure prediction as a general
              Bayesian inference problem. A distinctive feature of our approach
              is the ability to develop explicit probabilistic models for
              alpha-helices, beta-strands, and other classes of secondary
              structure, incorporating experimentally and empirically observed
              aspects of protein structure such as helical capping signals,
              side chain correlations, and segment length distributions. Our
              model is Markovian in the segments, permitting efficient exact
              calculation of the posterior probability distribution over all
              possible segmentations of the sequence using dynamic programming.
              The optimal segmentation is computed and compared to a predictor
              based on marginal posterior modes, and the latter is shown to
              provide significant improvement in predictive accuracy. The
              marginalization procedure provides exact secondary structure
              probabilities at each sequence position, which are shown to be
              reliable estimates of prediction uncertainty. We apply this model
              to a database of 452 nonhomologous structures, achieving
              accuracies as high as the best currently available methods. We
              conclude by discussing an extension of this framework to model
              nonlocal interactions in protein structures, providing a possible
              direction for future improvements in secondary structure
              prediction accuracy.",
  journal  = "Journal of Computational Biology",
  volume   =  7,
  number   = "1-2",
  pages    = "233--248",
  month    =  feb,
  year     =  2000,
  address  = "United States",
  language = "en"
}

@ARTICLE{Pitt1999-volatility,
  title     = "Filtering via Simulation: Auxiliary Particle Filters",
  author    = "Pitt, Michael K and Shephard, Neil",
  abstract  = "[This article analyses the recently suggested particle approach
               to filtering time series. We suggest that the algorithm is not
               robust to outliers for two reasons: the design of the simulators
               and the use of the discrete support to represent the
               sequentially updating prior distribution. Here we tackle the
               first of these problems.]",
  journal   = "Journal of the American Statistical Association",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  94,
  number    =  446,
  pages     = "590--599",
  year      =  1999
}


@ARTICLE{avitzour1995,
   author = {D. Avitzour},
   keywords = {Bayesian method;dense clutter;posterior state estimate distribution;state space;multitarget tracking;stochastic simulation;probabilistic data association;nearest-neighbours;},
   language = {English},
   abstract = {A stochastic simulation Bayesian method for multitarget tracking is developed. This method uses a random sample in state space to represent the posterior state estimate distribution. The method is illustrated by simulations involving one target in dense clutter. Comparison with nearest-neighbours and probabilistic data association shows the superiority of the proposed method.},
   title = {Stochastic simulation {B}ayesian approach to multitarget tracking},
   journal = {IEE Proceedings - Radar, Sonar and Navigation},
   issue = {2},   
   volume = {142},
   year = {1995},
   month = {April},
   pages = {41-44(3)}
}


@ARTICLE{rabiner1989,
  author={Rabiner, L.R.},
  journal={Proceedings of the IEEE}, 
  title={A tutorial on hidden {M}arkov models and selected applications in speech recognition}, 
  year={1989},
  volume={77},
  number={2},
  pages={257-286},
  keywords={Tutorial;Hidden Markov models;Speech recognition}}


@ARTICLE{gordon1993,
   author = {N.J. Gordon and D.J. Salmond and A.F.M. Smith},
   keywords = {state transition model;algorithm;bootstrap filter;recursive Bayesian filters;extended Kalman filter;simulation;measurement model;Gaussian noise;nonGaussian Bayesian state estimation;bearings only tracking problem;nonlinear Bayesian state estimation;state vector density;random samples;},
   language = {English},
   abstract = {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.},
   title = {Novel approach to nonlinear/non-{G}aussian {B}ayesian state estimation},
   journal = {IEE Proceedings F (Radar and Signal Processing)},
   issue = {2},   
   volume = {140},
   year = {1993},
   month = {April},
   pages = {107-113(6)},
   publisher ={}
}

@ARTICLE{stochasticEM,
  title     = "The Stochastic {EM} Algorithm: Estimation and Asymptotic Results",
  author    = "Nielsen, S{\o}ren Feodor",
  abstract  = "[The EM algorithm is a much used tool for maximum likelihood
               estimation in missing or incomplete data problems. However,
               calculating the conditional expectation required in the E-step
               of the algorithm may be infeasible, especially when this
               expectation is a large sum or a high-dimensional integral.
               Instead the expectation can be estimated by simulation. This is
               the common idea in the stochastic EM algorithm and the Monte
               Carlo EM algorithm. In this paper some asymptotic results for
               the Stochastic EM algorithm are given, and estimation based on
               this algorithm is discussed. In particular, asymptotic
               equivalence of certain simple estimators is shown, and a
               simulation experiment is carried out to investigate this
               equivalence in small and moderate samples. Furthermore, some
               implementation issues and the possibility of allowing
               unidentified parameters in the algorithm are discussed.]",
  journal   = "Bernoulli",
  publisher = "International Statistical Institute (ISI) and Bernoulli Society
               for Mathematical Statistics and Probability",
  volume    =  6,
  number    =  3,
  pages     = "457--489",
  year      =  2000
}


@article{Courant1943,
  author    = {R. Courant},
  title     = {Variational methods for the solution of problems of equilibrium and vibrations},
  journal   = {Bulletin of the American Mathematical Society},
  volume    = {49},
  number    = {1},
  pages     = {1--23},
  year      = {1943}
}

@article{Hadamard1908,
  author    = {Jacques Hadamard},
  title     = {M{\'e}moire sur le probl{\`e}me d'analyse relatif {\`a} l'{\'e}quilibre des plaques {\'e}lastiques encastr{\'e}es},
  journal   = {M{\'e}moires pr{\'e}sent{\'e}s par divers savants {\'e}strangers {\`a} l'Acad{\'e}mie des Sciences de l'Institut de France},
  volume    = {33},
  year      = {1908},
  language  = {French}
}

@article{Lemarechal2012,
  author    = {Claude Lemar{\'e}chal},
  title     = {Cauchy and the Gradient Method},
  journal   = {Doc Math Extra},
  pages     = {251--254},
  year      = {2012}
}

@ARTICLE{Breto2019-sz,
  title    = "Panel Data Analysis via Mechanistic Models",
  author   = "Bret{\'o}, Carles and Ionides, Edward L and King, Aaron A",
  abstract = "Panel data, also known as longitudinal data, consist of a
              collection of time series. Each time series, which could itself
              be multivariate, comprises a sequence of measurements taken on a
              distinct unit. Mechanistic modeling involves writing down
              scientifically motivated equations describing the collection of
              dynamic systems giving rise to the observations on each unit. A
              defining characteristic of panel systems is that the dynamic
              interaction between units should be negligible. Panel models
              therefore consist of a collection of independent stochastic
              processes, generally linked through shared parameters while also
              having unit-specific parameters. To give the scientist
              flexibility in model specification, we are motivated to develop a
              framework for inference on panel data permitting the
              consideration of arbitrary nonlinear, partially observed panel
              models. We build on iterated filtering techniques that provide
              likelihood-based inference on nonlinear partially observed Markov
              process models for time series data. Our methodology depends on
              the latent Markov process only through simulation; this
              plug-and-play property ensures applicability to a large class of
              models. We demonstrate our methodology on a toy example and two
              epidemiological case studies. We address inferential and
              computational issues arising due to the combination of model
              complexity and dataset size. Supplementary materials for this
              article are available online.",
  journal  = "Journal of the American Statistical Association",
  volume   =  115,
  number   =  531,
  pages    = "1178--1188",
  month    =  jun,
  year     =  2019,
  address  = "United States",
  keywords = "Likelihood; Longitudinal data; Nonlinear dynamics; Particle
              filter; Sequential Monte Carlo",
  language = "en"
}

@ARTICLE{Caron2011-al,
  title     = "{ON} {THE} {CONDITIONAL} {DISTRIBUTIONS} {OF} {SPATIAL} {POINT}
               {PROCESSES}",
  author    = "Caron, Fran{\c c}ois and del Moral, Pierre and Doucet, Arnaud
               and Pace, Michele",
  abstract  = "[We consider the problem of estimating a latent point process,
               given the realization of another point process. We establish an
               expression for the conditional distribution of a latent Poisson
               point process given the observation process when the
               transformation from the latent process to the observed process
               includes displacement, thinning, and augmentation with extra
               points. Our original analysis is based on an elementary and
               self-contained random measure theoretic approach. This
               simplifies and complements previous derivations given in Mahler
               (2003), and Singh, Vo, Baddeley and Zuyev (2009).]",
  journal   = "Advances in Applied Probability",
  publisher = "Applied Probability Trust",
  volume    =  43,
  number    =  2,
  pages     = "301--307",
  year      =  2011
}


@article{singhetal,
author = {Singh, Sumeetpal S. and Vo, Ba-Ngu and Baddeley, Adrian and Zuyev, Sergei},
title = {Filters for Spatial Point Processes},
journal = {SIAM Journal on Control and Optimization},
volume = {48},
number = {4},
pages = {2275-2295},
year = {2009},
    abstract = { We study the general problem of estimating a “hidden” point process \$\mathbf{X}\$, given the realization of an “observed” point process \$\mathbf{Y}\$ (possibly defined in different spaces) with known joint distribution. We characterize the posterior distribution of \$\mathbf{X}\$ under marginal Poisson and Gauss–Poisson priors and when the transformation from \$\mathbf{X}\$ to \$\mathbf{Y}\$ includes thinning, displacement, and augmentation with extra points. These results are then applied in a filtering context when the hidden process evolves in discrete time in a Markovian fashion. The dynamics of \$\mathbf{X}\$ considered are general enough for many target tracking applications. }
}


@ARTICLE{mahler,
  author={Mahler, R.P.S.},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={Multitarget {B}ayes filtering via first-order multitarget moments}, 
  year={2003},
  volume={39},
  number={4},
  pages={1152-1178},
  keywords={Filtering;Sensor systems;State-space methods;Virtual colonoscopy;Probability;Density measurement;Random number generation;Nonlinear filters;Terrorism;Contracts}}

@article{ensembkal,
author = {Evensen, Geir},
title = {Sequential data assimilation with a nonlinear quasi-geostrophic model using {M}onte {C}arlo methods to forecast error statistics},
journal = {Journal of Geophysical Research: Oceans},
volume = {99},
number = {C5},
pages = {10143-10162},
abstract = {A new sequential data assimilation method is discussed. It is based on forecasting the error statistics using Monte Carlo methods, a better alternative than solving the traditional and computationally extremely demanding approximate error covariance equation used in the extended Kalman filter. The unbounded error growth found in the extended Kalman filter, which is caused by an overly simplified closure in the error covariance equation, is completely eliminated. Open boundaries can be handled as long as the ocean model is well posed. Well-known numerical instabilities associated with the error covariance equation are avoided because storage and evolution of the error covariance matrix itself are not needed. The results are also better than what is provided by the extended Kalman filter since there is no closure problem and the quality of the forecast error statistics therefore improves. The method should be feasible also for more sophisticated primitive equation models. The computational load for reasonable accuracy is only a fraction of what is required for the extended Kalman filter and is given by the storage of, say, 100 model states for an ensemble size of 100 and thus CPU requirements of the order of the cost of 100 model integrations. The proposed method can therefore be used with realistic nonlinear ocean models on large domains on existing computers, and it is also well suited for parallel computers and clusters of workstations where each processor integrates a few members of the ensemble.},
year = {1994}
}


@ARTICLE{Rubin1987,
  title     = "The Calculation of Posterior Distributions by Data Augmentation:
               Comment: A Noniterative {Sampling/Importance} Resampling
               Alternative to the Data Augmentation Algorithm for Creating a
               Few Imputations When Fractions of Missing Information Are
               Modest: The {SIR} Algorithm",
  author    = "Rubin, Donald B",
  journal   = "Journal of the American Statistical Association",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  82,
  number    =  398,
  pages     = "543--546",
  year      =  1987
}


@ARTICLE{Kitagawa1996-wa,
  title     = "Monte {C}arlo Filter and Smoother for Non-{Gaussian} Nonlinear
               state space models",
  author    = "Kitagawa, Genshiro",
  abstract  = "[A new algorithm for the prediction, filtering, and smoothing of
               non-Gaussian nonlinear state space models is shown. The
               algorithm is based on a Monte Carlo method in which successive
               prediction, filtering (and subsequently smoothing), conditional
               probability density functions are approximated by many of their
               realizations. The particular contribution of this algorithm is
               that it can be applied to a broad class of nonlinear
               non-Gaussian higher dimensional state space models on the
               provision that the dimensions of the system noise and the
               observation noise are relatively low. Several numerical examples
               are shown.]",
  journal   = "Journal of Computational and Graphical Statistics",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  5,
  number    =  1,
  pages     = "1--25",
  year      =  1996
}



@article{SEIRmodel,
title = {A {SEIR} model for control of infectious diseases with constraints},
journal = {Mathematical Biosciences & Engineering},
volume = {11},
number = {4},
pages = {761-784},
year = {2014},
author = {M. H. A. Biswas and L. T. Paiva and MdR de Pinho},
keywords = {Optimal control, maximum principle, mixed constraints, state constraints, SEIR model, numerical applications}
}


@ARTICLE{seircov,
  title     = "{SARS-CoV-2} epidemic calculation in {I}taly by {SEIR}
               compartmental models",
  author    = "Battineni, Gopi and Chintalapudi, Nalini and Amenta, Francesco",
  abstract  = "Purpose After the identification of a novel severe acute
               respiratory syndrome coronavirus 2 (SARS-CoV-2) at Wuhan, China,
               a pandemic was widely spread worldwide. In Italy, about 240,000
               people were infected because of this virus including 34,721
               deaths until the end of June 2020. To control this new pandemic,
               epidemiologists recommend the enforcement of serious mitigation
               measures like country lockdown, contact tracing or testing,
               social distancing and self-isolation.
               Design/methodology/approach This paper presents the most popular
               epidemic model of susceptible (S), exposed (E), infected (I) and
               recovered (R) collectively called SEIR to understand the virus
               spreading among the Italian population. Findings Developed SEIR
               model explains the infection growth across Italy and presents
               epidemic rates after and before country lockdown. The results
               demonstrated that follow-up of strict measures such that country
               lockdown along with high testing is making Italy practically a
               pandemic-free country. Originality/value These models largely
               help to estimate and understand how an infectious agent spreads
               in a particular country and how individual factors can affect
               the dynamics. Further studies like classical SEIR modeling can
               improve the quality of data and implementation of this modeling
               could represent a novelty of epidemic models.",
  journal   = "Applied Computing and Informatics",
  publisher = "Emerald Publishing Limited",
  volume    = "ahead-of-print",
  month     =  jan,
  year      =  2020
}


@INPROCEEDINGS{wastewater,
  author={Jiang, Sihang and Maggard, Kristen and Shakeri, Heman and Porter, Michael D.},
  booktitle={2021 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={An Application of the Partially Observed {M}arkov Process in the Analysis of Transmission Dynamics of {COVID}-19 via Wastewater}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  keywords={COVID-19;Analytical models;RNA;Sociology;Markov processes;Coronaviruses;Wastewater;wastewater surveillance;partially observed Markov process;COVID-19;transmission dynamics;public health decision}}


@article{plospomp,
    author = {Doan, Tan N. AND Kong, David C. M. AND Marshall, Caroline AND Kirkpatrick, Carl M. J. AND McBryde, Emma S.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Characterising the Transmission Dynamics of {A}cinetobacter baumannii in Intensive Care Units Using Hidden {M}arkov Models},
    year = {2015},
    month = {07},
    volume = {10},
    pages = {1-15},
    abstract = {Little is known about the transmission dynamics of Acinetobacter baumannii in hospitals, despite such information being critical for designing effective infection control measures. In the absence of comprehensive epidemiological data, mathematical modelling is an attractive approach to understanding transmission process. The statistical challenge in estimating transmission parameters from infection data arises from the fact that most patients are colonised asymptomatically and therefore the transmission process is not fully observed. Hidden Markov models (HMMs) can overcome this problem. We developed a continuous-time structured HMM to characterise the transmission dynamics, and to quantify the relative importance of different acquisition sources of A. baumannii in intensive care units (ICUs) in three hospitals in Melbourne, Australia. The hidden states were the total number of patients colonised with A. baumannii (both detected and undetected). The model input was monthly incidence data of the number of detected colonised patients (observations). A Bayesian framework with Markov chain Monte Carlo algorithm was used for parameter estimations. We estimated that 96–98% of acquisition in Hospital 1 and 3 was due to cross-transmission between patients; whereas most colonisation in Hospital 2 was due to other sources (sporadic acquisition). On average, it takes 20 and 31 days for each susceptible individual in Hospital 1 and Hospital 3 to become colonised as a result of cross-transmission, respectively; whereas it takes 17 days to observe one new colonisation from sporadic acquisition in Hospital 2. The basic reproduction ratio (R0) for Hospital 1, 2 and 3 was 1.5, 0.02 and 1.6, respectively. Our study is the first to characterise the transmission dynamics of A. baumannii using mathematical modelling. We showed that HMMs can be applied to sparse hospital infection data to estimate transmission parameters despite unobserved events and imperfect detection of the organism. Our results highlight the need to optimise infection control in ICUs.},
    number = {7},

}
@article{HULIN2000197,
title = {Modelling the {HIV} epidemic: A state-space approach},
journal = {Mathematical and Computer Modelling},
volume = {32},
number = {1},
pages = {197-215},
year = {2000},
author = {Wu Hulin and Tan Wai-Yuan},
keywords = {HIV epidemic, Kalman filter, Kalman recursion, Projection of AIDS},
abstract = {A state-space approach is proposed for modelling the HIV epidemic. This model allows us to estimate and project the number of AIDS cases and the number of infective people at different stages using the Kalman recursion, in which we combine the information from the dynamic model and the observation of AIDS cases. The dynamic models (the state equations) are derived from the chain multinomial model proposed by Tan and his colleagues. The observation equations are the observed (reported) AIDS cases and the total system population which can be obtained by population survey. The methodology is illustrated by modelling the HIV epidemic in the homosexual population in the city of San Francisco. A brief discussion is given on the relationship between the backcalculation and our approach.}
}

@article{mseh,
author = {Michael A. Newton, Peter Guttorp, Sandra Catlin, Renato Assunção and Janis L. Abkowitz},
title = {Stochastic Modeling of Early {H}ematopoiesis},
journal = {Journal of the American Statistical Association},
volume = {90},
number = {432},
pages = {1146--1155},
year = {1995},
publisher = {Taylor \& Francis}
}


@article {ensemkalman2,
      author = "P. L. Houtekamer and Herschel L. Mitchell",
      title = "Data Assimilation Using an Ensemble {K}alman Filter Technique",
      journal = "Monthly Weather Review",
      year = "1998",
      publisher = "American Meteorological Society",
      address = "Boston MA, USA",
      volume = "126",
      number = "3",
      pages=      "796 - 811",
}
@article{kalman1960,
    Author = {Kalman, Rudolph Emil},
    Title = {A New Approach to Linear Filtering and Prediction Problems},
    Journal = {Transactions of the ASME--Journal of Basic Engineering},
    Volume = {82},
    Number = {Series D},
    Pages = {35--45},
    Year = {1960}
}


@article{iteratedfiltering,
author = {Edward L. Ionides and Anindya Bhadra and Yves Atchad{\'e} and Aaron King},
title = {{Iterated filtering}},
volume = {39},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1776 -- 1802},
keywords = {Dynamic systems, Filtering, importance sampling, partially observed Markov process, sequential Monte Carlo, state space model},
year = {2011}
}


@book{Chopin, place={Cham, Switzerland}, edition={1st}, series={Springer Series in Statistics, 0172-7397}, title={An introduction to Sequential {M}onte {C}arlo}, publisher={Springer}, author={Chopin, Nicolas and Papaspiliopoulos, Omiros}, year={2020}, collection={Springer Series in Statistics, 0172-7397} }

@book{liujun,
author = {Liu, Jun S.},
title = {Monte {C}arlo Strategies in Scientific Computing},
year = {2008},
publisher = {Springer Publishing Company, Incorporated},
abstract = {This paperback edition is a reprint of the 2001 Springer edition. This book provides a self-contained and up-to-date treatment of the Monte Carlo method and develops a common framework under which various Monte Carlo techniques can be "standardized" and compared. Given the interdisciplinary nature of the topics and a moderate prerequisite for the reader, this book should be of interest to a broad audience of quantitative researchers such as computational biologists, computer scientists, econometricians, engineers, probabilists, and statisticians. It can also be used as the textbook for a graduate-level course on Monte Carlo methods. Many problems discussed in the alter chapters can be potential thesis topics for masters or Ph.D. students in statistics or computer science departments. Jun Liu is Professor of Statistics at Harvard University, with a courtesy Professor appointment at Harvard Biostatistics Department. Professor Liu was the recipient of the 2002 COPSS Presidents' Award, the most prestigious one for statisticians and given annually by five leading statistical associations to one individual under age 40. He was selected as a Terman Fellow by Stanford University in 1995, as a Medallion Lecturer by the Institute of Mathematical Statistics (IMS) in 2002, and as a Bernoulli Lecturer by the International Bernoulli Society in 2004. He was elected to the IMS Fellow in 2004 and Fellow of the American Statistical Association in 2005. He and co-workers have published more than 130 research articles and book chapters on Bayesian modeling and computation, bioinformatics, genetics, signal processing, stochastic dynamic systems, Monte Carlo methods, and theoretical statistics. "An excellent survey of current Monte Carlo methods. The applications amply demonstrate the relevance of this approach to modern computing. The book is highly recommended." (Mathematical Reviews) "This book provides comprehensive coverage of Monte Carlo methods, and in the process uncovers and discusses commonalities among seemingly disparate techniques that arose in various areas of application. The book is well organized; the flow of topics follows a logical development. The coverage is up-to-date and comprehensive, and so the book is a good resource for people conducting research on Monte Carlo methods. The book would be an excellent supplementary text for a course in scientific computing ." (SIAM Review) "The strength of this book is in bringing together advanced Monte Carlo (MC) methods developed in many disciplines. Throughout the book are examples of techniques invented, or reinvented, in different fields that may be applied elsewhere. Those interested in using MC to solve difficult problems will find many ideas, collected from a variety of disciplines, and references for further study." (Technometrics)}
}



@article{pmcmc,
    author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
    title = "{Particle {M}arkov chain {M}onte {C}arlo methods}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {72},
    number = {3},
    pages = {269-342},
    year = {2010},
    month = {05},
    abstract = "{Markov chain Monte Carlo and sequential Monte Carlo methods have emerged as the two main tools to sample from high dimensional probability distributions. Although asymptotic convergence of Markov chain Monte Carlo algorithms is ensured under weak assumptions, the performance of these algorithms is unreliable when the proposal distributions that are used to explore the space are poorly chosen and/or if highly correlated variables are updated independently. We show here how it is possible to build efficient high dimensional proposal distributions by using sequential Monte Carlo methods. This allows us not only to improve over standard Markov chain Monte Carlo schemes but also to make Bayesian inference feasible for a large class of statistical models where this was not previously so. We demonstrate these algorithms on a non-linear state space model and a Lévy-driven stochastic volatility model.}"
}


@article{stocks,
    author = {Stocks, Theresa and Britton, Tom and Höhle, Michael},
    title = "{Model selection and parameter estimation for dynamic epidemic models via iterated filtering: application to rotavirus in {G}ermany}",
    journal = {Biostatistics},
    volume = {21},
    number = {3},
    pages = {400-416},
    year = {2018},
    month = {09},
    abstract = "{Despite the wide application of dynamic models in infectious disease epidemiology, the particular modeling of variability in the different model components is often subjective rather than the result of a thorough model selection process. This is in part because inference for a stochastic transmission model can be difficult since the likelihood is often intractable due to partial observability. In this work, we address the question of adequate inclusion of variability by demonstrating a systematic approach for model selection and parameter inference for dynamic epidemic models. For this, we perform inference for six partially observed Markov process models, which assume the same underlying transmission dynamics, but differ with respect to the amount of variability they allow for. The inference framework for the stochastic transmission models is provided by iterated filtering methods, which are readily implemented in the R package pomp by King and others (2016, Statistical inference for partially observed Markov processes via the R package pomp. Journal of Statistical Software69, 1–43). We illustrate our approach on German rotavirus surveillance data from 2001 to 2008, discuss practical difficulties of the methods used and calculate a model based estimate for the basic reproduction number \\$R\_0\\$ using these data.}",
}




@ARTICLE{timeseries,
  title    = "Time series regression studies in environmental epidemiology",
  author   = "Bhaskaran, Krishnan and Gasparrini, Antonio and Hajat, Shakoor
              and Smeeth, Liam and Armstrong, Ben",
  abstract = "Time series regression studies have been widely used in
              environmental epidemiology, notably in investigating the
              short-term associations between exposures such as air pollution,
              weather variables or pollen, and health outcomes such as
              mortality, myocardial infarction or disease-specific hospital
              admissions. Typically, for both exposure and outcome, data are
              available at regular time intervals (e.g. daily pollution levels
              and daily mortality counts) and the aim is to explore short-term
              associations between them. In this article, we describe the
              general features of time series data, and we outline the analysis
              process, beginning with descriptive analysis, then focusing on
              issues in time series regression that differ from other
              regression methods: modelling short-term fluctuations in the
              presence of seasonal and long-term patterns, dealing with time
              varying confounding factors and modelling delayed ('lagged')
              associations between exposure and outcome. We finish with advice
              on model checking and sensitivity analysis, and some common
              extensions to the basic model.",
  journal  = "Int J Epidemiol",
  volume   =  42,
  number   =  4,
  pages    = "1187--1195",
  month    =  jun,
  year     =  2013,
  address  = "England",
  keywords = "Time series; air pollution; environmental epidemiology",
  language = "en"
}


@article{daihai,
author = {He, Daihai  and Ionides, Edward L.  and King, Aaron A. },
title = {Plug-and-play inference for disease dynamics: measles in large and small populations as a case study},
journal = {Journal of The Royal Society Interface},
volume = {7},
number = {43},
pages = {271-283},
year = {2010},
    abstract = { Statistical inference for mechanistic models of partially observed dynamic systems is an active area of research. Most existing inference methods place substantial restrictions upon the form of models that can be fitted and hence upon the nature of the scientific hypotheses that can be entertained and the data that can be used to evaluate them. In contrast, the so-called plug-and-play methods require only simulations from a model and are thus free of such restrictions. We show the utility of the plug-and-play approach in the context of an investigation of measles transmission dynamics. Our novel methodology enables us to ask and answer questions that previous analyses have been unable to address. Specifically, we demonstrate that plug-and-play methods permit the development of a modelling and inference framework applicable to data from both large and small populations. We thereby obtain novel insights into the nature of heterogeneity in mixing and comment on the importance of including extra-demographic stochasticity as a means of dealing with environmental stochasticity and model misspecification. Our approach is readily applicable to many other epidemiological and ecological systems. }
}

@article{wwr,
    author = {Whitehouse, Michael and Whiteley, Nick and Rimella, Lorenzo},
    title = "{Consistent and fast inference in compartmental models of epidemics using {P}oisson {A}pproximate {L}ikelihoods}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {85},
    number = {4},
    pages = {1173-1203},
    year = {2023},
    month = {07},
    abstract = "{Addressing the challenge of scaling-up epidemiological inference to complex and heterogeneous models, we introduce Poisson approximate likelihood (PAL) methods. In contrast to the popular ordinary differential equation (ODE) approach to compartmental modelling, in which a large population limit is used to motivate a deterministic model, PALs are derived from approximate filtering equations for finite-population, stochastic compartmental models, and the large population limit drives consistency of maximum PAL estimators. Our theoretical results appear to be the first likelihood-based parameter estimation consistency results which apply to a broad class of partially observed stochastic compartmental models and address the large population limit. PALs are simple to implement, involving only elementary arithmetic operations and no tuning parameters, and fast to evaluate, requiring no simulation from the model and having computational cost independent of population size. Through examples we demonstrate how PALs can be used to: fit an age-structured model of influenza, taking advantage of automatic differentiation in Stan; compare over-dispersion mechanisms in a model of rotavirus by embedding PALs within sequential Monte Carlo; and evaluate the role of unit-specific parameters in a meta-population model of measles.}"
}



