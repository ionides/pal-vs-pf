\documentclass[10pt]{article}
\usepackage{color}
\usepackage{graphicx} % Required for inserting 
%%\usepackage{algpseudocode} % Include the package for algorithmic environment
\usepackage{algorithm}
\usepackage{booktabs} % For better-quality horizontal lines
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{threeparttable} % For table notes
\usepackage{array} % For table formatting

\usepackage{setspace}
\usepackage{float} % add this in your preamble
\usepackage{amsmath}
\usepackage{tabularx}

\newcommand{\ed}[1]{\textcolor{red}{[EI:#1]}}
\newcommand{\yize}[1]{\textcolor{green}{[YH:#1]}}
\newcommand{\aaron}[1]{\textcolor{blue}{[AA:#1]}}

\usepackage[round]{natbib}

\usepackage{multirow}
\usepackage{fourier} 
\usepackage{booktabs}
\usepackage{array}
\usepackage{makecell}
\usepackage[font={small,it}]{caption}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{tabstackengine}
\usepackage[toc,page]{appendix}
\usepackage{graphicx, fullpage, verbatim, amsmath}
\usepackage{url, amsfonts, amssymb, amsthm,color, enumerate}
\usepackage{placeins, listings, textcomp, mathtools, multicol, tikz}
\usepackage{dsfont}
\usepackage{amsfonts}
\usepackage{bm}



\TABstackMath

\doublespacing
% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{graphicx}
\bibliographystyle{apalike}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
\newcommand\choleraDeath{\delta_{C}}

% Using \doublespacing in the preamble 
% changes the text to double-line spacing
\doublespacing


\begin{document}

\title{The Poisson approximate likelihood compared to the particle filter}
\author{Yize Hao, Aaron A. Abkemeier and Edward L. Ionides}
\date{Draft compiled on \today}
\maketitle

\begin{abstract}
Filtering algorithms are fundamental for inference on partially observed stochastic dynamic systems, since they provide access to the likelihood function and hence enable likelihood-based or Bayesian inference.
Recently, a novel Poisson approximate likelihood (PAL) filter was introduced by \cite{wwr}.
PAL employs a Poisson approximation to conditional densities, offering a fast and consistent approximation to the likelihood function for a certain subset of partially observed Markov process models.
\cite{wwr} supported the importance of their contribution by theoretical analysis and numerical results.
A central piece of evidence for PAL is the comparison in Table~1 of \cite{wwr}, which claims a large improvement for PAL over a standard particle filter algorithm.
This evidence, based on a model and data from a previous scientific study, suggests at face value that researchers confronted with similar models would be irresponsible not to adopt PAL.
We show that the evidence is flawed because the PAL calculations were carried out using a dataset differently scaled from the previous study.
If PAL and the particle filter are used on this new scale, the superficial advantage of PAL largely disappears.
On simulations where the model is correctly specified, the particle filter outperforms PAL.
If a poorly fitting specification of initial value parameters is ammended, the particle filter also outperforms PAL on the actual data.
\end{abstract}


% R starts here

<<setup,echo=FALSE,message=FALSE,warning=FALSE>>=
rm(list = ls())     # clear objects

library("knitr")
opts_knit$set(concordance=TRUE)
opts_chunk$set(
    concordance = TRUE,
    tidy = TRUE,
    message = FALSE,
    warning = FALSE,
    tidy.opts = list(
        keep.blank.line = FALSE
    ),
    comment = "",
    echo = FALSE,
    results = FALSE,
    dev.args = list(
        bg = "transparent",
        pointsize = 9
    ),
    fig.path = "figure/"
)

myround <- function(x, digits = 1) {
  # taken from the broman package
  if (digits < 1)
    stop("This is intended for the case digits >= 1.")
  if (length(digits) > 1) {
    digits <- digits[1]
    warning("Using only digits[1]")
  }
  tmp <- sprintf(paste("%.", digits, "f", sep = ""), x)
  zero <- paste0("0.", paste(rep("0", digits), collapse = ""))
  tmp[tmp == paste0("-", zero)] <- zero
  tmp
}

graphics.off()      # close graphics windows
library(pomp)
library(magrittr)
library(plyr)
library(reshape2)
library(ggplot2)
library(scales)
library(foreach)
library(doParallel)
registerDoParallel()
stopifnot(packageVersion("pomp") >= "1.7")

RUN_LEVEL = 1
NP_MIF       = switch(RUN_LEVEL, 4, 50000)
NMIF         = switch(RUN_LEVEL, 4,  100)
ncores       = switch(RUN_LEVEL, 4,  36)
@


% OvOv model is here

<<OvOv-model>>=
# measurement model 
dmeas <- Csnippet("
                  if (ISNA(cases1)) {
                  lik = (give_log) ? 0 : 1;
                  } else {
                        lik =  dbinom(cases1, H1, q1, 1) +
                        dbinom(cases2, H2, q2, 1) +
                        dbinom(cases3, H3, q3, 1);
                      
                    lik = (give_log) ? lik : exp(lik);
                        
                    }")
rmeas <-  Csnippet("
                    cases1 = rbinom(H1, q1);
                    cases2 = rbinom(H2, q2);
                    cases3 = rbinom(H3, q3);
                  ")



rproc <- Csnippet("
    int I = I1 + I2 + I3;
    int trans_S1[3], trans_S2[3], trans_S3[2], trans_I1[3], trans_I2[3], trans_I3[2], trans_R1[3], trans_R2[3], trans_R3[2];
    
    double prob_S1[3],prob_I1[3],prob_R1[3],prob_S2[3],prob_I2[3],prob_R2[3],prob_S3[2],prob_I3[2],prob_R3[2];
    
    double xi = rgamma(sigma_xi, 1/sigma_xi);
    
    double kappa = (1 + beta11*cos(2*3.141593*t/52 + phi)) * xi;
    
    // Define rate
    prob_S1[0] = 1-exp(-dt*beta1*kappa*I/N); // 0->1
    prob_S1[1] = 1-exp(-delta1*dt);
    prob_S1[2] = exp(-delta1*dt) + exp(-dt*beta1*kappa*I/N) - 1;
    
    prob_I1[0] = 1-exp(-gamma*dt);
    prob_I1[1] = 1-exp(-delta1*dt);
    prob_I1[2] = exp(-gamma*dt)+exp(-delta1*dt) - 1;
    
    prob_R1[0] = 1 - exp(-omega*dt);  // E_1,t this goes back to S_1,(t+1)
    prob_R1[1] = 1 - exp(-delta1*dt);
    prob_R1[2] = exp(-omega*dt) + exp(-delta1*dt) - 1;
    
    prob_S2[0] = 1-exp(-dt*beta2*kappa*I/N);
    prob_S2[1] = 1-exp(-delta2*dt);
    prob_S2[2] = exp(-delta2*dt) + exp(-dt*beta2*kappa*I/N) - 1;
    
    prob_I2[0] = 1-exp(-dt*gamma);
    prob_I2[1] = 1-exp(-dt*delta2);
    prob_I2[2] = exp(-dt*gamma)+exp(-dt*delta2) - 1;
    
    prob_R2[0] = 1 - exp(-dt*omega);  // E_1,t this goes back to S_1,(t+1)
    prob_R2[1] = 1 - exp(-dt*delta2);
    prob_R2[2] = exp(-dt*omega) + exp(-dt*delta2) - 1;
    
    // For Age Group (3): Die first before transition;
    
    int S3mD, I3mD, R3mD;
    
    S3mD = rbinom(S3, 1-dt*mu); // S3 minus Death: mu is the death rate, so it's 1-mu here
    I3mD = rbinom(I3, 1-dt*mu);
    R3mD = rbinom(R3, 1-dt*mu);
    
    prob_S3[0] = 1-exp(-dt*beta3*kappa*I/N);
    prob_S3[1] = exp(-dt*beta3*kappa*I/N);
    
    prob_I3[0] = 1 - exp(-dt*gamma);
    prob_I3[1] = exp(-dt*gamma);
    
    prob_R3[0] = 1 - exp(-dt*omega);
    prob_R3[1] = exp(-dt*omega);
    
    // Transition
    // B: S->I
    // C: I->R
    // F: Aging: (1)->(2)->(3)
    // E: R->S
    // D: Death
    //// Note: Here S_1, S_2... are all old value from (t-1)
    rmultinom(S1, &prob_S1, 3, &trans_S1); // B, F, S-B-F
    rmultinom(I1, &prob_I1, 3, &trans_I1); // C, F, I-C-F
    rmultinom(R1, &prob_R1, 3, &trans_R1); // E, F, R-E-F
    
    rmultinom(S2, &prob_S2, 3, &trans_S2); // B, F, S-B-F
    rmultinom(I2, &prob_I2, 3, &trans_I2); // C, F, I-C-F
    rmultinom(R2, &prob_R2, 3, &trans_R2); // E, F, R-E-F
    
    rmultinom(S3mD, &prob_S3, 2, &trans_S3); // B, (S-D)-B
    rmultinom(I3mD, &prob_I3, 2, &trans_I3); // C, (I-D)-C
    rmultinom(R3mD, &prob_R3, 2, &trans_R3); // E, (R-D)-E
    
    S1 = trans_S1[2] + trans_R1[0] + rpois(4*1025.7); // Include Birth
    I1 = trans_I1[2] + trans_S1[0];
    R1 = trans_R1[2] + trans_I1[0];
    
    S2 = trans_S2[2] + trans_R2[0] + trans_S1[1]; // Include Aging
    I2 = trans_I2[2] + trans_S2[0] + trans_I1[1];
    R2 = trans_R2[2] + trans_I2[0] + trans_R1[1];
    
    S3 = trans_S3[1] + trans_R3[0] + trans_S2[1]; // Include Aging
    I3 = trans_I3[1] + trans_S3[0] + trans_I2[1];
    R3 = trans_R3[1] + trans_I3[0] + trans_R2[1];
    
    //Accumvar
    H1 += trans_S1[0];
    H2 += trans_S2[0];
    H3 += trans_S3[0];
    
    q1 = -1; 
    while(q1 < 0 || q1 > 1){
      q1 = rnorm(0.07, sigma_q);
    }
    
    q2 = -1; 
    while(q2 < 0 || q2 > 1){
      q2 = rnorm(0.07, sigma_q);
    }
    
    q3 = -1; 
    while(q3 < 0 || q3 > 1){
      q3 = rnorm(0.07, sigma_q);
    }
")


# define parameters (without betas)
params_fixed <- c(gamma=1, delta1=1/(5*52),delta2=1/(55*52), alpha=1/(78.86912*52), 
                  mu=0, N=82372825, omega=1/(1*52))
# WWR's rinit
rinit <- Csnippet("
    double m = N/(S10+I10+R10+S20+I20+R20+S30+I30+R30);
    I1=nearbyint(m*I10);
    I2=nearbyint(m*I20);
    I3=nearbyint(m*I30);
    S1=nearbyint(m*S10);
    S2=nearbyint(m*S20);
    S3=nearbyint(m*S30);
    R1=nearbyint(m*R10);
    R2=nearbyint(m*R20);
    R3=nearbyint(m*R30);
    H1 = 0;
    H2 = 0;
    H3 = 0;
")

# Set to MLE
params_stocks_stst_mle <- params_fixed

params_stocks_stst_mle["beta1"] <- 11.48
params_stocks_stst_mle["beta2"] <- 0.25
params_stocks_stst_mle["beta3"] <- 0.35
params_stocks_stst_mle["phi"] <- 0.14
params_stocks_stst_mle["beta11"] <- 0.16
params_stocks_stst_mle["sigma_q"] <- 0.021
params_stocks_stst_mle["sigma_xi"] <- 66.89
params_stocks_stst_mle["S10"] <- 0.047061
params_stocks_stst_mle["I10"] <- 0.000368
params_stocks_stst_mle["R10"] <- 0.015967
params_stocks_stst_mle["S20"] <- 0.015967
params_stocks_stst_mle["I20"] <- 0.000011
params_stocks_stst_mle["R20"] <- 0.003677
params_stocks_stst_mle["S30"] <- 0.237624
params_stocks_stst_mle["I30"] <- 0.000031
params_stocks_stst_mle["R30"] <- 0.001591
@


% Maximization Round 1

<<maximization1>>=
pt <- pomp::parameter_trans(
  log = c("beta1","beta2","beta3","sigma_q","sigma_xi"),
  logit=c("beta11"),
  barycentric=c("S10","I10","R10",
                "S20","I20","R20",
                "S30","I30","R30"),
  toEst= pomp::Csnippet("T_phi = logit(phi/(M_2PI));"),
  fromEst= pomp::Csnippet("phi = M_2PI*expit(T_phi);")
)

read.table("real_rotavirus_metadata.txt") %>%
  rbind(data.frame(time=0,cases1=NA,cases2=NA,cases3=NA)) %>%
  arrange(time) -> dat


pomp(data = dat,
     times="time",
     t0=0,
     dmeasure = dmeas,
     rmeasure = rmeas,
     rprocess = discrete_time(step.fun = rproc, delta.t = 1/4),
     statenames = c("S1", "I1", "R1", "H1", 
                    "S2", "I2", "R2", "H2",
                    "S3", "I3", "R3", "H3", 
                    "q1", "q2", "q3"),
     paramnames = names(params_stocks_stst_mle),
     accumvars=c("H1", "H2", "H3"),
     rinit=rinit,
     partrans = pt,
     params = params_stocks_stst_mle
) -> sir

sir_panel <- panelPomp::panelPomp(list(unit1=sir),
                                  shared=NULL,
                                  specific=params_stocks_stst_mle |> 
                                    as.matrix() |>
                                    `colnames<-`("unit1")
)

require(doParallel)
cores <- ncores
registerDoParallel(cores)
mcopts <- list(set.seed=TRUE)


sir_box <- rbind(
  beta1=c(10,15),
  beta2=c(0.2,0.4),
  beta3=c(0.3,0.5),
  phi=c(0.01,0.3),
  beta11=c(0.1,0.2),
  sigma_q=c(0.001,0.1),
  sigma_xi=c(65,70),
  S10 = c(0.01,0.05),
  I10 = c(0.0001, 0.0005),
  R10 = c(0.01, 0.05),
  S20 = c(0.01,0.7),
  I20 = c(0.000001,0.00002),
  R20 = c(0.001,0.005),
  S30 = c(0.01,0.5),
  I30 = c(0.000001, 0.0001),
  R30 = c(0.0001,0.005)
)


## Make it panelPomp
c(apply(sir_box,1,function(x)runif(1,min=x[1],max=x[2])),
  params_fixed) |> 
  as.matrix() |>
  `colnames<-`("unit1") -> starting

bake(file = "output/round_01/ovov_mif_01.rds",{ 
  mifs_global <- foreach(i=1:cores,.packages='pomp', .options.multicore=mcopts) %dopar% {
    panelPomp::mif2(
      sir_panel,
      Np = NP_MIF,
      cooling.fraction.50 = 0.5,
      rw.sd = rw_sd(beta1=0.01,beta2=0.01,beta3=0.01,
                    beta11=0.01,phi=0.01,sigma_q=0.01,sigma_xi=0.01,
                    S10=ivp(0.24),I10=ivp(0.24),R10=ivp(0.24),
                    S20=ivp(0.24),I20=ivp(0.24),R20=ivp(0.24),
                    S30=ivp(0.24),I30=ivp(0.24),R30=ivp(0.24)),
      cooling.type = "geometric",
      Nmif = NMIF,
      shared.start = numeric(0),
      specific.start = starting,
      block = F
    ) 
  }
  mifs_global
})

bake(file = "output/round_01/ovov_01_el.rds",{
  el <- measlespkg::eval_logLik(mifs_global, ncores=cores, np_pf = NP_MIF, nreps=cores)
  el
})
@


% Continue: Maximization Round 2

<<maximization2>>=
sd           = 2/3
top_n_fits   = 12
# measurement model 
dmeas <- Csnippet("
                  if (ISNA(cases1)) {
                  lik = (give_log) ? 0 : 1;
                  } else {
                        lik =  dbinom(cases1, H1, q1, 1) +
                        dbinom(cases2, H2, q2, 1) +
                        dbinom(cases3, H3, q3, 1);
                      
                    lik = (give_log) ? lik : exp(lik);
                        
                    }")
rmeas <-  Csnippet("
                    cases1 = rbinom(H1, q1);
                    cases2 = rbinom(H2, q2);
                    cases3 = rbinom(H3, q3);
                  ")



rproc <- Csnippet("
    int I = I1 + I2 + I3;
    int trans_S1[3], trans_S2[3], trans_S3[2], trans_I1[3], trans_I2[3], trans_I3[2], trans_R1[3], trans_R2[3], trans_R3[2];
    
    double prob_S1[3],prob_I1[3],prob_R1[3],prob_S2[3],prob_I2[3],prob_R2[3],prob_S3[2],prob_I3[2],prob_R3[2];
    
    double xi = rgamma(sigma_xi, 1/sigma_xi);
    
    double kappa = (1 + beta11*cos(2*3.141593*t/52 + phi)) * xi;
    
    // Define rate
    prob_S1[0] = 1-exp(-dt*beta1*kappa*I/N); // 0->1
    prob_S1[1] = 1-exp(-delta1*dt);
    prob_S1[2] = exp(-delta1*dt) + exp(-dt*beta1*kappa*I/N) - 1;
    
    prob_I1[0] = 1-exp(-gamma*dt);
    prob_I1[1] = 1-exp(-delta1*dt);
    prob_I1[2] = exp(-gamma*dt)+exp(-delta1*dt) - 1;
    
    prob_R1[0] = 1 - exp(-omega*dt);  // E_1,t this goes back to S_1,(t+1)
    prob_R1[1] = 1 - exp(-delta1*dt);
    prob_R1[2] = exp(-omega*dt) + exp(-delta1*dt) - 1;
    
    prob_S2[0] = 1-exp(-dt*beta2*kappa*I/N);
    prob_S2[1] = 1-exp(-delta2*dt);
    prob_S2[2] = exp(-delta2*dt) + exp(-dt*beta2*kappa*I/N) - 1;
    
    prob_I2[0] = 1-exp(-dt*gamma);
    prob_I2[1] = 1-exp(-dt*delta2);
    prob_I2[2] = exp(-dt*gamma)+exp(-dt*delta2) - 1;
    
    prob_R2[0] = 1 - exp(-dt*omega);  // E_1,t this goes back to S_1,(t+1)
    prob_R2[1] = 1 - exp(-dt*delta2);
    prob_R2[2] = exp(-dt*omega) + exp(-dt*delta2) - 1;
    
    // For Age Group (3): Die first before transition;
    
    int S3mD, I3mD, R3mD;
    
    S3mD = rbinom(S3, 1-dt*mu); // S3 minus Death: mu is the death rate, so it's 1-mu here
    I3mD = rbinom(I3, 1-dt*mu);
    R3mD = rbinom(R3, 1-dt*mu);
    
    prob_S3[0] = 1-exp(-dt*beta3*kappa*I/N);
    prob_S3[1] = exp(-dt*beta3*kappa*I/N);
    
    prob_I3[0] = 1 - exp(-dt*gamma);
    prob_I3[1] = exp(-dt*gamma);
    
    prob_R3[0] = 1 - exp(-dt*omega);
    prob_R3[1] = exp(-dt*omega);
    
    // Transition
    // B: S->I
    // C: I->R
    // F: Aging: (1)->(2)->(3)
    // E: R->S
    // D: Death
    //// Note: Here S_1, S_2... are all old value from (t-1)
    rmultinom(S1, &prob_S1, 3, &trans_S1); // B, F, S-B-F
    rmultinom(I1, &prob_I1, 3, &trans_I1); // C, F, I-C-F
    rmultinom(R1, &prob_R1, 3, &trans_R1); // E, F, R-E-F
    
    rmultinom(S2, &prob_S2, 3, &trans_S2); // B, F, S-B-F
    rmultinom(I2, &prob_I2, 3, &trans_I2); // C, F, I-C-F
    rmultinom(R2, &prob_R2, 3, &trans_R2); // E, F, R-E-F
    
    rmultinom(S3mD, &prob_S3, 2, &trans_S3); // B, (S-D)-B
    rmultinom(I3mD, &prob_I3, 2, &trans_I3); // C, (I-D)-C
    rmultinom(R3mD, &prob_R3, 2, &trans_R3); // E, (R-D)-E
    
    S1 = trans_S1[2] + trans_R1[0] + rpois(4*1025.7); // Include Birth
    I1 = trans_I1[2] + trans_S1[0];
    R1 = trans_R1[2] + trans_I1[0];
    
    S2 = trans_S2[2] + trans_R2[0] + trans_S1[1]; // Include Aging
    I2 = trans_I2[2] + trans_S2[0] + trans_I1[1];
    R2 = trans_R2[2] + trans_I2[0] + trans_R1[1];
    
    S3 = trans_S3[1] + trans_R3[0] + trans_S2[1]; // Include Aging
    I3 = trans_I3[1] + trans_S3[0] + trans_I2[1];
    R3 = trans_R3[1] + trans_I3[0] + trans_R2[1];
    
    //Accumvar
    H1 += trans_S1[0];
    H2 += trans_S2[0];
    H3 += trans_S3[0];
    
    q1 = -1; 
    while(q1 < 0 || q1 > 1){
      q1 = rnorm(0.07, sigma_q);
    }
    
    q2 = -1; 
    while(q2 < 0 || q2 > 1){
      q2 = rnorm(0.07, sigma_q);
    }
    
    q3 = -1; 
    while(q3 < 0 || q3 > 1){
      q3 = rnorm(0.07, sigma_q);
    }
")


# define parameters (without betas)
params_fixed <- c(gamma=1, delta1=1/(5*52),delta2=1/(55*52), alpha=1/(78.86912*52), 
                  mu=0, N=82372825, omega=1/(1*52))
# WWR's rinit
rinit <- Csnippet("
    double m = N/(S10+I10+R10+S20+I20+R20+S30+I30+R30);
    I1=nearbyint(m*I10);
    I2=nearbyint(m*I20);
    I3=nearbyint(m*I30);
    S1=nearbyint(m*S10);
    S2=nearbyint(m*S20);
    S3=nearbyint(m*S30);
    R1=nearbyint(m*R10);
    R2=nearbyint(m*R20);
    R3=nearbyint(m*R30);
    H1 = 0;
    H2 = 0;
    H3 = 0;
")

# Set to MLE
params_stocks_stst_mle <- params_fixed

params_stocks_stst_mle["beta1"] <- 11.48
params_stocks_stst_mle["beta2"] <- 0.25
params_stocks_stst_mle["beta3"] <- 0.35
params_stocks_stst_mle["phi"] <- 0.14
params_stocks_stst_mle["beta11"] <- 0.16
params_stocks_stst_mle["sigma_q"] <- 0.021
params_stocks_stst_mle["sigma_xi"] <- 66.89
params_stocks_stst_mle["S10"] <- 0.047061
params_stocks_stst_mle["I10"] <- 0.000368
params_stocks_stst_mle["R10"] <- 0.015967
params_stocks_stst_mle["S20"] <- 0.015967
params_stocks_stst_mle["I20"] <- 0.000011
params_stocks_stst_mle["R20"] <- 0.003677
params_stocks_stst_mle["S30"] <- 0.237624
params_stocks_stst_mle["I30"] <- 0.000031
params_stocks_stst_mle["R30"] <- 0.001591



pt <- pomp::parameter_trans(
  log = c("beta1","beta2","beta3","sigma_q","sigma_xi"),
  logit=c("beta11"),
  barycentric=c("S10","I10","R10",
                "S20","I20","R20",
                "S30","I30","R30"),
  toEst= pomp::Csnippet("T_phi = logit(phi/(M_2PI));"),
  fromEst= pomp::Csnippet("phi = M_2PI*expit(T_phi);")
)

read.table("real_rotavirus_metadata.txt") %>%
  rbind(data.frame(time=0,cases1=NA,cases2=NA,cases3=NA)) %>%
  arrange(time) -> dat


pomp(data = dat,
     times="time",
     t0=0,
     dmeasure = dmeas,
     rmeasure = rmeas,
     rprocess = discrete_time(step.fun = rproc, delta.t = 1/4),
     statenames = c("S1", "I1", "R1", "H1", 
                    "S2", "I2", "R2", "H2",
                    "S3", "I3", "R3", "H3", 
                    "q1", "q2", "q3"),
     paramnames = names(params_stocks_stst_mle),
     accumvars=c("H1", "H2", "H3"),
     rinit=rinit,
     partrans = pt,
     params = params_stocks_stst_mle
) -> sir

sir_panel <- panelPomp::panelPomp(list(unit1=sir),
                                  shared=NULL,
                                  specific=params_stocks_stst_mle |> 
                                    as.matrix() |>
                                    `colnames<-`("unit1")
)

require(doParallel)
cores <- ncores
registerDoParallel(cores)
mcopts <- list(set.seed=TRUE)

### Next-round code
el <- readRDS("output/round_01/ovov_01_el.rds")
x <- na.omit(el$fits)
score_total = x$logLik
ranking_total = order(score_total, decreasing = TRUE)[1:top_n_fits]

best_fits = dplyr::select(
  x[ranking_total,], -"logLik", -"se"
)

recycle_vec = sort(rep_len(1:top_n_fits, cores))
full_best_fit <- best_fits[recycle_vec, ] 

coef_names <- colnames(full_best_fit)
colnames(full_best_fit) <- gsub(".{7}$","",coef_names)

starting_values <- vector(cores, mode="list")

for(i in 1:cores){
  t(full_best_fit[i, ])  |> 
    as.matrix() |>
    `colnames<-`("unit1") -> starting_values[[i]] 
}

mifs_global <- foreach(i=1:cores,.packages='pomp', .options.multicore=mcopts) %dopar% {
  panelPomp::mif2(
    sir_panel,
    Np = NP_MIF,
    cooling.fraction.50 = 0.5,
    rw.sd = rw_sd(beta1=0.01*sd,beta2=0.01*sd,beta3=0.01*sd,
                  beta11=0.01*sd,phi=0.01*sd,sigma_q=0.01*sd,sigma_xi=0.01*sd,
                  S10=ivp(0.24)*sd,I10=ivp(0.24)*sd,R10=ivp(0.24)*sd,
                  S20=ivp(0.24)*sd,I20=ivp(0.24)*sd,R20=ivp(0.24)*sd,
                  S30=ivp(0.24)*sd,I30=ivp(0.24)*sd,R30=ivp(0.24)*sd),
    cooling.type = "geometric",
    Nmif = NMIF,
    shared.start = numeric(0),
    specific.start = starting_values[[i]],
    block = F
  ) 
}

bake(file = "output/round_02/ovov_mif_02.rds",{ 
  mifs_global
})

bake(file = "output/round_02/ovov_02_el.rds",{
  el <- measlespkg::eval_logLik(mifs_global, ncores = cores, np_pf = NP_MIF, nreps=cores)
  el
})
@

% Continue: Maximization Round 3

<<maximization3>>=
sd           = (2/3)^2
top_n_fits   = 12
# measurement model 
dmeas <- Csnippet("
                  if (ISNA(cases1)) {
                  lik = (give_log) ? 0 : 1;
                  } else {
                        lik =  dbinom(cases1, H1, q1, 1) +
                        dbinom(cases2, H2, q2, 1) +
                        dbinom(cases3, H3, q3, 1);
                      
                    lik = (give_log) ? lik : exp(lik);
                        
                    }")
rmeas <-  Csnippet("
                    cases1 = rbinom(H1, q1);
                    cases2 = rbinom(H2, q2);
                    cases3 = rbinom(H3, q3);
                  ")



rproc <- Csnippet("
    int I = I1 + I2 + I3;
    int trans_S1[3], trans_S2[3], trans_S3[2], trans_I1[3], trans_I2[3], trans_I3[2], trans_R1[3], trans_R2[3], trans_R3[2];
    
    double prob_S1[3],prob_I1[3],prob_R1[3],prob_S2[3],prob_I2[3],prob_R2[3],prob_S3[2],prob_I3[2],prob_R3[2];
    
    double xi = rgamma(sigma_xi, 1/sigma_xi);
    
    double kappa = (1 + beta11*cos(2*3.141593*t/52 + phi)) * xi;
    
    // Define rate
    prob_S1[0] = 1-exp(-dt*beta1*kappa*I/N); // 0->1
    prob_S1[1] = 1-exp(-delta1*dt);
    prob_S1[2] = exp(-delta1*dt) + exp(-dt*beta1*kappa*I/N) - 1;
    
    prob_I1[0] = 1-exp(-gamma*dt);
    prob_I1[1] = 1-exp(-delta1*dt);
    prob_I1[2] = exp(-gamma*dt)+exp(-delta1*dt) - 1;
    
    prob_R1[0] = 1 - exp(-omega*dt);  // E_1,t this goes back to S_1,(t+1)
    prob_R1[1] = 1 - exp(-delta1*dt);
    prob_R1[2] = exp(-omega*dt) + exp(-delta1*dt) - 1;
    
    prob_S2[0] = 1-exp(-dt*beta2*kappa*I/N);
    prob_S2[1] = 1-exp(-delta2*dt);
    prob_S2[2] = exp(-delta2*dt) + exp(-dt*beta2*kappa*I/N) - 1;
    
    prob_I2[0] = 1-exp(-dt*gamma);
    prob_I2[1] = 1-exp(-dt*delta2);
    prob_I2[2] = exp(-dt*gamma)+exp(-dt*delta2) - 1;
    
    prob_R2[0] = 1 - exp(-dt*omega);  // E_1,t this goes back to S_1,(t+1)
    prob_R2[1] = 1 - exp(-dt*delta2);
    prob_R2[2] = exp(-dt*omega) + exp(-dt*delta2) - 1;
    
    // For Age Group (3): Die first before transition;
    
    int S3mD, I3mD, R3mD;
    
    S3mD = rbinom(S3, 1-dt*mu); // S3 minus Death: mu is the death rate, so it's 1-mu here
    I3mD = rbinom(I3, 1-dt*mu);
    R3mD = rbinom(R3, 1-dt*mu);
    
    prob_S3[0] = 1-exp(-dt*beta3*kappa*I/N);
    prob_S3[1] = exp(-dt*beta3*kappa*I/N);
    
    prob_I3[0] = 1 - exp(-dt*gamma);
    prob_I3[1] = exp(-dt*gamma);
    
    prob_R3[0] = 1 - exp(-dt*omega);
    prob_R3[1] = exp(-dt*omega);
    
    // Transition
    // B: S->I
    // C: I->R
    // F: Aging: (1)->(2)->(3)
    // E: R->S
    // D: Death
    //// Note: Here S_1, S_2... are all old value from (t-1)
    rmultinom(S1, &prob_S1, 3, &trans_S1); // B, F, S-B-F
    rmultinom(I1, &prob_I1, 3, &trans_I1); // C, F, I-C-F
    rmultinom(R1, &prob_R1, 3, &trans_R1); // E, F, R-E-F
    
    rmultinom(S2, &prob_S2, 3, &trans_S2); // B, F, S-B-F
    rmultinom(I2, &prob_I2, 3, &trans_I2); // C, F, I-C-F
    rmultinom(R2, &prob_R2, 3, &trans_R2); // E, F, R-E-F
    
    rmultinom(S3mD, &prob_S3, 2, &trans_S3); // B, (S-D)-B
    rmultinom(I3mD, &prob_I3, 2, &trans_I3); // C, (I-D)-C
    rmultinom(R3mD, &prob_R3, 2, &trans_R3); // E, (R-D)-E
    
    S1 = trans_S1[2] + trans_R1[0] + rpois(4*1025.7); // Include Birth
    I1 = trans_I1[2] + trans_S1[0];
    R1 = trans_R1[2] + trans_I1[0];
    
    S2 = trans_S2[2] + trans_R2[0] + trans_S1[1]; // Include Aging
    I2 = trans_I2[2] + trans_S2[0] + trans_I1[1];
    R2 = trans_R2[2] + trans_I2[0] + trans_R1[1];
    
    S3 = trans_S3[1] + trans_R3[0] + trans_S2[1]; // Include Aging
    I3 = trans_I3[1] + trans_S3[0] + trans_I2[1];
    R3 = trans_R3[1] + trans_I3[0] + trans_R2[1];
    
    //Accumvar
    H1 += trans_S1[0];
    H2 += trans_S2[0];
    H3 += trans_S3[0];
    
    q1 = -1; 
    while(q1 < 0 || q1 > 1){
      q1 = rnorm(0.07, sigma_q);
    }
    
    q2 = -1; 
    while(q2 < 0 || q2 > 1){
      q2 = rnorm(0.07, sigma_q);
    }
    
    q3 = -1; 
    while(q3 < 0 || q3 > 1){
      q3 = rnorm(0.07, sigma_q);
    }
")


# define parameters (without betas)
params_fixed <- c(gamma=1, delta1=1/(5*52),delta2=1/(55*52), alpha=1/(78.86912*52), 
                  mu=0, N=82372825, omega=1/(1*52))
# WWR's rinit
rinit <- Csnippet("
    double m = N/(S10+I10+R10+S20+I20+R20+S30+I30+R30);
    I1=nearbyint(m*I10);
    I2=nearbyint(m*I20);
    I3=nearbyint(m*I30);
    S1=nearbyint(m*S10);
    S2=nearbyint(m*S20);
    S3=nearbyint(m*S30);
    R1=nearbyint(m*R10);
    R2=nearbyint(m*R20);
    R3=nearbyint(m*R30);
    H1 = 0;
    H2 = 0;
    H3 = 0;
")

# Set to MLE
params_stocks_stst_mle <- params_fixed

params_stocks_stst_mle["beta1"] <- 11.48
params_stocks_stst_mle["beta2"] <- 0.25
params_stocks_stst_mle["beta3"] <- 0.35
params_stocks_stst_mle["phi"] <- 0.14
params_stocks_stst_mle["beta11"] <- 0.16
params_stocks_stst_mle["sigma_q"] <- 0.021
params_stocks_stst_mle["sigma_xi"] <- 66.89
params_stocks_stst_mle["S10"] <- 0.047061
params_stocks_stst_mle["I10"] <- 0.000368
params_stocks_stst_mle["R10"] <- 0.015967
params_stocks_stst_mle["S20"] <- 0.015967
params_stocks_stst_mle["I20"] <- 0.000011
params_stocks_stst_mle["R20"] <- 0.003677
params_stocks_stst_mle["S30"] <- 0.237624
params_stocks_stst_mle["I30"] <- 0.000031
params_stocks_stst_mle["R30"] <- 0.001591



pt <- pomp::parameter_trans(
  log = c("beta1","beta2","beta3","sigma_q","sigma_xi"),
  logit=c("beta11"),
  barycentric=c("S10","I10","R10",
                "S20","I20","R20",
                "S30","I30","R30"),
  toEst= pomp::Csnippet("T_phi = logit(phi/(M_2PI));"),
  fromEst= pomp::Csnippet("phi = M_2PI*expit(T_phi);")
)

read.table("real_rotavirus_metadata.txt") %>%
  rbind(data.frame(time=0,cases1=NA,cases2=NA,cases3=NA)) %>%
  arrange(time) -> dat


pomp(data = dat,
     times="time",
     t0=0,
     dmeasure = dmeas,
     rmeasure = rmeas,
     rprocess = discrete_time(step.fun = rproc, delta.t = 1/4),
     statenames = c("S1", "I1", "R1", "H1", 
                    "S2", "I2", "R2", "H2",
                    "S3", "I3", "R3", "H3", 
                    "q1", "q2", "q3"),
     paramnames = names(params_stocks_stst_mle),
     accumvars=c("H1", "H2", "H3"),
     rinit=rinit,
     partrans = pt,
     params = params_stocks_stst_mle
) -> sir

sir_panel <- panelPomp::panelPomp(list(unit1=sir),
                                  shared=NULL,
                                  specific=params_stocks_stst_mle |> 
                                    as.matrix() |>
                                    `colnames<-`("unit1")
)

require(doParallel)
cores <- ncores
registerDoParallel(cores)
mcopts <- list(set.seed=TRUE)

### Next-round code
el <- readRDS("output/round_02/ovov_02_el.rds")
x <- na.omit(el$fits)
score_total = x$logLik
ranking_total = order(score_total, decreasing = TRUE)[1:top_n_fits]

best_fits = dplyr::select(
  x[ranking_total,], -"logLik", -"se"
)

recycle_vec = sort(rep_len(1:top_n_fits, cores))
full_best_fit <- best_fits[recycle_vec, ] 

coef_names <- colnames(full_best_fit)
colnames(full_best_fit) <- gsub(".{7}$","",coef_names)

starting_values <- vector(cores, mode="list")

for(i in 1:cores){
  t(full_best_fit[i, ])  |> 
    as.matrix() |>
    `colnames<-`("unit1") -> starting_values[[i]] 
}

mifs_global <- foreach(i=1:cores,.packages='pomp', .options.multicore=mcopts) %dopar% {
  panelPomp::mif2(
    sir_panel,
    Np = NP_MIF,
    cooling.fraction.50 = 0.5,
    rw.sd = rw_sd(beta1=0.01*sd,beta2=0.01*sd,beta3=0.01*sd,
                  beta11=0.01*sd,phi=0.01*sd,sigma_q=0.01*sd,sigma_xi=0.01*sd,
                  S10=ivp(0.24)*sd,I10=ivp(0.24)*sd,R10=ivp(0.24)*sd,
                  S20=ivp(0.24)*sd,I20=ivp(0.24)*sd,R20=ivp(0.24)*sd,
                  S30=ivp(0.24)*sd,I30=ivp(0.24)*sd,R30=ivp(0.24)*sd),
    cooling.type = "geometric",
    Nmif = NMIF,
    shared.start = numeric(0),
    specific.start = starting_values[[i]],
    block = F
  ) 
}

bake(file = "output/round_03/ovov_mif_03.rds",{ 
  mifs_global
})

bake(file = "output/round_03/ovov_03_el.rds",{
  el <- measlespkg::eval_logLik(mifs_global, ncores = cores, np_pf = NP_MIF, nreps=cores)
  el
})
@

%%%%%%%%%% 11111111 %%%%%%%%%%%%

\section{Introduction}

%% \ed{WE WILL NEED TO WORD THIS CAREFULLY. WE MUST BE FORCEFUL ABOUT THE VALUE OF CORRECTING THE SCIENTIFIC RECORD, WITHOUT SEEMING UNNECESSARILY CONFRONTATIONAL. ONE WAY TO DO THIS IS TO BE COMPLIMENTARY ABOUT PAL AS MUCH AS POSSIBLE. AFTER ALL, IF THE METHOD HAS SOME GOOD PROPERTIES THEN THIS ADDS VALUE TO UNDERSTANDING PROPERLY ITS LIMITATIONS. I'VE REWRITTEN THE ABSTRACT FROM THAT PERSPECTIVE.}

%% \ed{AT THIS POINT, THE DRAFT IS QUITE PROVISIONAL, PUTTING THINGS IN PLACE SO IT CAN BE REFINED LATER.}

This article results from an investigation of the results in Table~1 of \citet{wwr}.
The authors of that paper were given the opportunity to submit a correction, after we shared the results of our investigation with them, but they declined.
Our task here is to correct the error in Table~1 so that researchers considering whether to implement Poisson approximate likelihood (PAL) are appropriately informed about its benefits.
Table~1 reanalyzes the model and data of \citet{stocks}, for which the likelihood was calculated using a particle filter.
The theory developed by \cite{wwr} shows that PAL has some potentially useful scaling properties, but the numerical results in Table~1 appear to show much stronger performance than the particle filter on this example of moderate size.

First, we show that most of this apparent improvement for PAL arises because \cite{wwr} used a different scaling of the data from \cite{stocks}.
%% \section{Comparing PAL with the particle filter} 
Two models for the same data can properly be compared by their likelihood, even if the models have entirely different structures.
One can making allowance for the number of estimated parameters using a quantity such as Akaike's information criterion [REF].
However, if data are rescaled, a correction is required to make likelihoods comparable.
If one model describes a dataset in grams, and another describes it in kilograms, then the latter model will earn an increased log-likelihood of $\log(10^3)$ for each data point simply because of the change in scale.
Presenting a direct comparison of a likelihood for the data in grams with a likelihood for the data in kilograms would evidently be inapprpriate.
\cite{stocks} fitted their model to a dataset derived by dividing the original reported count data by an estimated reporting rate, to put their data on the scale of the actual number of cases in the population.
\cite{wwr} fitted directly to the report data.
The reporting rate used by \cite{stocks} varied over time, but was generally around $7\%$.
On 1200 data points, this corresponds to a discrepancy of around $-1200\log(0.07)=3200$ log-likelihood units, largely explaining the difference reported in Table~1 and interpreted by \cite{wwr} as evidence supporting PAL.
The comparison can be corrected either by applying the method of \cite{stocks} to the data of \cite{wwr} or vvice versa.
Since the method of \cite{stocks} is applicable to a more general class of models, and supported by published software, it was more convenient to apply this method to the model and data of \cite{wwr}.
The large discrepancy in log-likelihood disappears at this point (see our Table~\ref{tab:ovovrealdata} , column \ed{XXX}).
This re-analysis does, however, show a small advantage for PAL.
We continued our investigation to establish the cause of this.


PAL provides an approximate filter, whereas the particle filter provides a Monte~Carlo estimate of an exact filter.
Possible explanations for PAL obtaining a higher log-likelihood than a particle filter include:
\begin{enumerate}
\item The particle filter could have high Monte Carlo variance. This results in negative bias in its log-likilihood estimate due to Jensen's inequality, since the particle filter provides an unbiased likelihood estimate.
\item If the model is misspecified, the approximation error in PAL could lead to a higher log-likelihood estimate than that of the actual misspecified model.
\end{enumerate}
Log-likelihood is a proper scoring rule for forecasts \cite{gneiting2}, and both the particle filter and PAL construct their log-likelihood estimates via a sequence of one-step forecasts.
%% resulting in estimates of the conditional log-likelihood, $f_{Y
Therefore, if the model is correctly specified, the approximation error in PAL can only decrease the expected log-likelihood.
We tested this on simulated data, for which the model of \cite{wwr} is correctly specified.
We found that, in this case, the particle filter out-performs PAL \ed{SHOW RESULTS}.
This supports hypothesis 2, above.
We looked for model misspecification by comparing the conditional log-likelihood estimates at each time point, as described in the Methods section.
Figure~ \ref{fig:cond_SMC_PAL_realdat} indicates that the model provides a poor explanation of the data right at the start of the time series.
This could be a problem with data collection, or some subtle issue with the science of the epidemiological system, but a simple possibility is that the initial values of the latent state process might be poorly specified.
For this model, the initial values were fixed based on scientific reasoning, rather than being estimated.
If we instead estimate the initial values, we obtain the results in \ed{XXXX}. 

\ed{WE CAN REVIEW EXACTLY WHICH NUMBERS TO SHOW. IDEALLY, AS LITTLE AS POSSIBLE IN ORDER TO MAKE A STRONG ARGUMENT.}

We conclude that PAL is a potentially useful algorithm, with some favorable theoretical properties.
However, the corrected evidence does not indicate an advantage for using PAL in situations where the particle filter is effective.


\section{Methods}

\ed{BRIEFLY DESCRIBE HERE ANY DETAILS NEEDED TO DESCRIBE THE RESULTS. COMMENT ON CODE AVAILABILITY.}

To evaluate whether SMC performs as well as PAL in terms of both computational time and likelihood identifiability, we replicated the model using the R package \textbf{pomp} \citep{pomppackagepaper}. First, we verified that the two models are essentially identical. Here, we simulated data from the model 1000 times at the MLE shown in Table \ref{tab:mlebywwr} and compared the summary statistics of 1000 simulated time series from two models using the t-test. Summary statistics including the mean, median, and variance for all three age groups were tested. The results showed no significant differences between the two models from which the data were simulated, confirming that both the latent process model and the observation model are essentially consistent with each other, given that the observations were directly simulated.

From Table \ref{tab:model_performance}, it is evident that the OvOv model, with overdispersion in both the dynamic system and the measurement model, yields the lowest AIC.
We therefore focus on this version of the model.

To examine the model misspecification at potential time points, as depicted in Figure \ref{fig:cond_SMC_PAL_realdat}, the majority of significant drops of the SMC occurred at time ($t=1, \,\,2, \,\,3, \,\,11, \,\,81, \,\,194, \,\,325-333$). The significant drops observed initially, specifically at times $t=1, 2, 3$, may suggest an improper initial distribution from which the first set of particles was simulated. At times $t=11, \,\,81, \,\,194$ and $t=325-333$, the shortfall approximated $50-100$ log-units.
These failures can be attributed to outliers that the model cannot explain, as shown in \ed{XXXX}.
This suggests model misspecification, particularly in the latent process, which fails to generate suitable particles capable of producing a high likelihood of observing the true reported cases from the data.
Subsequent issues observed at later times could indicate problems caused by fixed seasonality, which cannot be compensated for by adding more stochastic elements. 

This article has focused on likelihood evaluation, but the inferences presented also require the likelihood estimate to maximized.
\cite{stocks} used iterated filtering to maximize the particle filter likelihood estimate, whereas \cite{wwr} used direct numerical maximization.
We follow the approaches adopted by these two papers.
The optimization method is not directly pertinent to the comparison of the filtering methods, so we do not discuss optimization in further detail here.


\begin{table}[htbp]
  \centering
  \begin{threeparttable}
    \caption{Maximum likelihood estimation of parameters by PAL for three models \citep{wwr}, and by mif2 algorithm \citep{pomppackagepaper} for the OvOv model.}
    \label{tab:mlebywwr}
    \begin{tabular}{>{\raggedright\arraybackslash}p{2cm} *{3}{>{\centering\arraybackslash}p{1.5cm}} >{\centering\arraybackslash}p{2.5cm}}
      \toprule
      Parameter      & EqEq  & EqOv  & OvOv  & OvOv (\textbf{pomp})$^*$ \\
      \midrule
      \(\beta_1\)    & 12.15 & 12.74 & 11.48 & $\Sexpr{'test'}$\\
      \(\beta_2\)    & 0.22  & 0.21  & 0.25  & $\Sexpr{'test'}$\\
      \(\beta_3\)    & 0.34  & 0.31  & 0.35  & $\Sexpr{'test'}$\\
      \(\phi\)       & 0.017 & 0.14  & 0.14  & $\Sexpr{'test'}$\\
      \(\rho\)       & 0.022 & 0.19  & 0.16  & $\Sexpr{'test'}$\\
      \(\sigma^2_q\) & n/a   & 0.042 & 0.021 & $\Sexpr{'test'}$\\
      \(\sigma_\xi\) & n/a   & n/a   & 66.89 & $\Sexpr{'test'}$\\
      \addlinespace
      \multicolumn{1}{l}{\(S_{10}\)} & \multicolumn{3}{c}{$3876549^*$} & $5885201$\\
      \multicolumn{1}{l}{\(I_{10}\)} & \multicolumn{3}{c}{$30351$}     & $5041$\\
      \multicolumn{1}{l}{\(R_{10}\)} & \multicolumn{3}{c}{$1315221$}   & $721006$\\
      \multicolumn{1}{l}{\(S_{20}\)} & \multicolumn{3}{c}{$57139612$}  & $44546887$\\
      \multicolumn{1}{l}{\(I_{20}\)} & \multicolumn{3}{c}{$871$}       & $22$\\
      \multicolumn{1}{l}{\(R_{20}\)} & \multicolumn{3}{c}{$302852$}    & $26360811$\\
      \multicolumn{1}{l}{\(S_{30}\)} & \multicolumn{3}{c}{$19573727$}  & $4788420$\\
      \multicolumn{1}{l}{\(I_{30}\)} & \multicolumn{3}{c}{$2550$}      & $131$\\
      \multicolumn{1}{l}{\(R_{30}\)} & \multicolumn{3}{c}{$131092$}    & $65306$\\
      \midrule
      \addlinespace
      \textbf{AIC}  & $98866.65$ & $15154.75$ & $13778.08$ & $\Sexpr{'test'}$\\
      \addlinespace
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \small
      \item[*] The initial distribution parameter \(\lambda_0 = (S_{10}, I_{10}, R_{10}, S_{20}, I_{20}, R_{20}, S_{30}, I_{30}, R_{30})\) are assumed to be \textbf{fixed} in \cite{wwr}. The results of the estimates of the OvOv (\textbf{pomp}) model are obtained by using the Iterated Filtering algorithm with 3 rounds and 100 iterations, 50,000 particles, and 36 replicates in each round with the top 12 best fits in terms of likelihood chosen to be the starting value for the next round. 
    \end{tablenotes}
  \end{threeparttable}
\end{table}


Our results demonstrate how SMC is sensitive to model misspecification, which consequently leads to a low likelihood estimate at the MLE, as shown in Table \ref{tab:ovovrealdata} by fitting the real German rotavirus dataset into the model.

\begin{table}[ht] % The placement specifier can be [h!tbp]
\centering % Centers the table
\caption{log-likelihood at the MLE of OvOv model for the real rotavirus data, computed using two filtering methods, employed 36 replicates and 50,000 particles} % This is effectively the table title
\label{tab:ovovrealdata} % For referencing this table elsewhere in your text
\begin{tabular}{|c c c|} 
 \hline
  & PAL & SMC  \\
  \hline
 OvOv & -6892.168 & -7200.866 \\ 
 \hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{thesis-figs/cond_SMC_PAL_realdat.png}
\caption{\label{fig:cond_SMC_PAL_realdat}Conditional log-likelihoods computed using two methods for the real rotavirus dataset, with the SMC method replicated 36 times due to its high variances. The blue line represents overlapping results from 36 SMC computations, while the red line is derived from PAL. The main sources of likelihood shortfall of SMC are at time points $t=1, 2, 3, 11, 81, 194$, and $325-333$.}
\end{figure}

\vspace{-8mm}
\subsection{PAL versus SMC: When the Model is Correctly Specified}\label{section3}

Here, we utilize 100 simulated datasets from the OvOv model with parameters set at the MLE, thereby eliminating model misspecification. We then examine the likelihood values computed by PAL and SMC.


\begin{table}[htbp] % The placement specifier can be [h!tbp]
\centering % Centers the table
\caption{Average log-likelihood at the MLE at the 100 simulated datasets from OvOv computed by two filtering methods, employed 36 replicates and 50,000 particles} % This is effectively the table title
\label{tab:ovovtrue} % For referencing this table elsewhere in your text
\begin{tabular}{|c c c|} 
 \hline
  & PAL & SMC  \\ 
 \hline
 OvOv & -6231.97 & -6224.245 \\ 
 \hline
\end{tabular}
\end{table}
\begin{figure}[H]
\centering
\vspace{-7mm}
\includegraphics[width=0.55\textwidth]{thesis-figs/PAL_vs_SMC_ovov_100.png}
\caption{\label{fig:PAL_vs_SMC_ovov_100}Log-likelihoods computed using two filtering methods for 100 randomly simulated datasets at the MLE of the OvOv model. The red line is the line $Lik(pfilter)=Lik(palfilter)$. We can see on the simulated data, SMC gives consistently higher likelihood estimates than PAL.}
\end{figure}



Notably, Section~\ref{misspecified} reveals that when the model confronts actual rotavirus data, it encounters misspecification issues, particularly at times $t=1, \,\,2, \,\,3, \,\,11, \,\,81, \,\,194, \,\,325-333$, leading to shortfalls in likelihood. Appendix \ref{appendB} discusses this phenomenon, attributing it to certain data points that the model fails to adequately represent. This issue is especially pronounced at the initial time points. Particularly, in the initial time points $t=1,2,3$, the likelihood deviates from PAL estimates for about more than 100 log-likelihood units, suggesting an improper choice of initial distribution that might favor the PAL estimate. Consequently, we have opted to estimate the initial distribution \(\lambda_0 = (S_{10}, I_{10}, R_{10}, S_{20}, I_{20}, R_{20}, S_{30}, I_{30}, R_{30})\), where $S_{10}, I_{10}, R_{10}, S_{20}, I_{20}, R_{20}, S_{30}, I_{30}$, and $R_{30}$ represent the number of individuals in each compartment at time $t=0$. The results of this new estimation can be found in Table \ref{tab:mlebywwr}. Importantly, the maximization of the likelihood conducted via the Iterated Filtering (mif2) algorithm \citep{pomppackagepaper} procures a higher likelihood at the estimated MLE than that estimated by PAL, and a different yet comparable set of estimates is obtained. In terms of parameters pertinent to epidemiological interests, i.e. the first 7 rows in Table \ref{tab:mlebywwr}, we observe a lower force of infection parameter for the first age group, $\beta_1$, alongside a higher force of infection for the third age group, $\beta_3$. Additionally, we detect variations in the phase parameter $\phi$, which directly affects the seasonal time points, as well as in the stochastic parameter $\sigma_{\xi}$ and the initial compartmental distributions. The modifications to the initial distributions aim to rectify inadequate initialization, while the other adjustments address model misspecifications identified in Section \ref{misspecified}. Changes in the remaining parameter set are negligible.




PAL is an approximate filtering method used in scenarios where SMC is computationally prohibitive. It approximates the posterior distribution by a Poisson approximation. Due to its approximative nature, it does not perfectly capture the true posterior distribution. 
SMC, however, often referred to as the "perfect filter," uses a large set of particles and sophisticated resampling techniques to theoretically accurately approximate the posterior distribution. It is computationally more intensive than PAL but tends to provide a satisfying approximation, especially in complex models that are not compatible with PAL in general. When PAL and SMC are applied to a well-specified model meaning the model with the latent process model being correctly represented, SMC outperforms PAL because it better captures the nuances of the posterior distribution. This is why SMC might show a "likelihood shortfall" compared to PAL when the model is correctly specified. This is due to the approximation error of PAL can't be improved arbitrarily in general \citep{annurev:/content/journals/10.1146/annurev-control-042920-015119}, and likelihood being a proper scoring rule.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{thesis-figs/plot_zoom_png.png}
\caption{\label{fig:zoomedin_outlier_plot} Zoomed-in time-Cases plot at time $t=0-20, 75-85, 190-200$ and $320-340$. In the visualization, solid lines represent the true reported cases from the original rotavirus dataset, while the shaded strips with dashed boundaries-colored according to different groupsâ€”indicate enlarged "confidence intervals" for these cases. Specifically, the upper boundary of each strip corresponds to the upper 97.5\% percentile of 36 replicates of the filtered accumulated number of cases, $H_{kt}$, for $k=1,2,3$, and $t=1,2,...,416$, as introduced in Section \ref{observationmodel}. This boundary is further adjusted by the upper 97.5\% percentile of the reporting rate $q_t$, estimated by \cite{wwr} in Table \ref{tab:mlebywwr}. The reporting rate $q_t$ is assumed to follow a truncated normal distribution with a mean of 0.07 and a standard deviation of $\sigma_q = 0.021$, resulting in a lower 2.5\% percentile of 0.029 and an upper 97.5\% percentile of 0.111. The methodology for establishing the lower boundary of the strip mirrors that of the upper boundary. Although this approach is not entirely rigorous, each strip is intended to encompass our extended confidence interval for the true reported cases. Consequently, data points that fall outside these strips give us a intuition of where the model misspecifications may occur.}
\end{figure}

As illustrated in Figure \ref{fig:cond_SMC_PAL_realdat}, shortfalls are observed at times $t=1,\,\,2,\,\,3,\,\,11,\,\,81,\,\,194,$ and $325-333$. These discrepancies are primarily attributable to outliers that the model fails to accommodate. In the displayed results, it is immediately apparent that at the initial times $t=1, \,\,2, \,\,3$ all the true reported cases deviated from the expected range, falling outside the designated strip. Specifically, at time $t=11$, the model is misspecified for case 1, depicted by the solid red line. Similarly, at times $t=81,\,\, 82$, the model is misspecified for case 3, as indicated by the solid blue line that extended beyond the strip's boundaries. At $t=194$, the solid green line denotes case 2 as where the model is misspecified. During the period from $t=325-333$, all three observed cases are where the model misspecifications happen. These deviations provide a clear illustration of the likelihood shortfall of the sequential Monte Carlo (SMC) method when the model does not align with the data, suggesting a model misspecification. 

\bibliography{bib-pal}

\end{document}
