\documentclass[10pt]{article}
\usepackage{color}
\usepackage{graphicx} % Required for inserting
\usepackage{booktabs} % For better-quality horizontal lines
\usepackage{multirow}
\usepackage{makecell}
% \usepackage{threeparttable} % For table notes
\usepackage{array} % For table formatting
\usepackage{subcaption}
\usepackage{setspace} % For double-line spacing
\usepackage{float} 
\usepackage{tabularx}
\usepackage[round]{natbib}
\usepackage[font={small,it}]{caption}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage{verbatim}
\usepackage{amsfonts,amssymb,amsthm}
\usepackage{url}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
% Using \doublespacing in the preamble 
% changes the text to double-line spacing
\doublespacing

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\newcommand{\ed}[1]{\textcolor{red}{[EI:#1]}}
\newcommand{\yize}[1]{\textcolor{green}{[YH:#1]}}
\newcommand{\aaron}[1]{\textcolor{blue}{[AA:#1]}}

\bibliographystyle{apalike}

\begin{document}

\title{The Poisson approximate likelihood compared to the particle filter}
\author{Yize Hao, Aaron A. Abkemeier and Edward L. Ionides}
\date{Draft compiled on \today}
\maketitle

\begin{abstract}
Filtering algorithms are fundamental for inference on partially observed stochastic dynamic systems, since they provide access to the likelihood function and hence enable likelihood-based or Bayesian inference.
A novel Poisson approximate likelihood (PAL) filter was introduced by \cite{wwr}.
PAL employs a Poisson approximation to conditional densities, offering a fast and consistent approximation to the likelihood function for a certain subset of partially observed Markov process models.
A central piece of evidence for PAL is the comparison in Table~1 of \cite{wwr}, which claims a large improvement for PAL over a standard particle filter algorithm.
This evidence, based on a model and data from a previous scientific study by \citet{stocks}, might suggests that researchers confronted with similar models should use PAL rather than previous particle filter methods.
Alternatively, the improvement in likelihood found by \cite{wwr} compared to \cite{stocks} might indicate a flaw in the model or numerical methods for that previous work.
We show that neither of these conclusions is valid, and the comparison of log-likelihood values made by \cite{wwr} is flawed because the PAL calculations were carried out using a dataset scaled differently from the previous study.
If PAL and the particle filter are used on this new scale, the superficial advantage of PAL largely disappears.
On simulations where the model is correctly specified, the particle filter outperforms PAL.
If a poorly fitting specification of initial value parameters is amended, the particle filter also outperforms PAL on the actual data.
\end{abstract}


% R starts here

<<setup,echo=FALSE,message=FALSE,warning=FALSE>>=
rm(list = ls())     # clear objects

library("knitr")
opts_knit$set(concordance=TRUE)
opts_chunk$set(
  tidy = TRUE,
# message = FALSE,
# warning = FALSE,
  tidy.opts = list(
    keep.blank.line = FALSE
  ),
  comment = "",
  echo = FALSE,
  results = FALSE,
  dev.args = list(
    bg = "transparent",
    pointsize = 9
  ),
  fig.path = "figure/"
)

myround <- function(x, digits = 1) {
  # taken from the broman package
  if (digits < 1)
    stop("This is intended for the case digits >= 1.")
  if (length(digits) > 1) {
    digits <- digits[1]
    warning("Using only digits[1]")
  }
  tmp <- sprintf(paste("%.", digits, "f", sep = ""), x)
  zero <- paste0("0.", paste(rep("0", digits), collapse = ""))
  tmp[tmp == paste0("-", zero)] <- zero
  tmp
}

graphics.off()      # close graphics windows
library(pomp)
library(ggplot2)
library(scales)
library(foreach)
library(doParallel)
library(doFuture)
library(dplyr)
library(Rcpp)
library(RcppArmadillo)
sourceCpp('rotavirus_normq.cpp')
source("choose_n_fits.R")
source("eval_logLik_pomp.R")

RUN_LEVEL = 3
NP_MIF       = switch(RUN_LEVEL, 10,   5000,  50000)
NMIF         = switch(RUN_LEVEL, 5,    20,    100)
ncores       = switch(RUN_LEVEL, 4,    10,    36)
top_n_fits   = switch(RUN_LEVEL, 1,    2,     12)
sim_rep      = switch(RUN_LEVEL, 5,    20,    100) #sim_ovov

#population number
pop <- 82372825
time <- c(1:416)

out_dir <- paste0("output_0",RUN_LEVEL, "/")
@


% OvOv model is here

<<OvOv-model, echo=F, warning=F, message=F>>=
# measurement model 
dmeas <- Csnippet("
  lik =  dbinom(cases1, H1, q1, 1) +
  dbinom(cases2, H2, q2, 1) +
  dbinom(cases3, H3, q3, 1);"
)
rmeas <-  Csnippet("
  cases1 = rbinom(H1, q1);
  cases2 = rbinom(H2, q2);
  cases3 = rbinom(H3, q3);
")

rproc <- Csnippet("
  int I = I1 + I2 + I3;
  int trans_S1[3], trans_S2[3], trans_S3[2], trans_I1[3], trans_I2[3], 
  trans_I3[2], trans_R1[3], trans_R2[3], trans_R3[2];
    
  double prob_S1[3], prob_I1[3], prob_R1[3], prob_S2[3], prob_I2[3], prob_R2[3],
  prob_S3[2], prob_I3[2], prob_R3[2];
    
  double xi = rgamma(sigma_xi, 1/sigma_xi);
    
  double kappa = (1 + beta11*cos(2*3.141593*t/52 + phi)) * xi;
    
  // Define rate
  prob_S1[0] = 1 - exp(-dt*beta1*kappa*I/N); // 0->1
  prob_S1[1] = 1 - exp(-delta1*dt);
  prob_S1[2] = exp(-delta1*dt) + exp(-dt*beta1*kappa*I/N) - 1;
    
  prob_I1[0] = 1 - exp(-gamma*dt);
  prob_I1[1] = 1 - exp(-delta1*dt);
  prob_I1[2] = exp(-gamma*dt)+exp(-delta1*dt) - 1;
    
  prob_R1[0] = 1 - exp(-omega*dt);  // E_1,t this goes back to S_1,(t+1)
  prob_R1[1] = 1 - exp(-delta1*dt);
  prob_R1[2] = exp(-omega*dt) + exp(-delta1*dt) - 1;
    
  prob_S2[0] = 1 - exp(-dt*beta2*kappa*I/N);
  prob_S2[1] = 1 - exp(-delta2*dt);
  prob_S2[2] = exp(-delta2*dt) + exp(-dt*beta2*kappa*I/N) - 1;
    
  prob_I2[0] = 1 - exp(-dt*gamma);
  prob_I2[1] = 1 - exp(-dt*delta2);
  prob_I2[2] = exp(-dt*gamma)+exp(-dt*delta2) - 1;
    
  prob_R2[0] = 1 - exp(-dt*omega);  // E_1,t this goes back to S_1,(t+1)
  prob_R2[1] = 1 - exp(-dt*delta2);
  prob_R2[2] = exp(-dt*omega) + exp(-dt*delta2) - 1;
    
  // For Age Group (3): Die first before transition;
    
  int S3mD, I3mD, R3mD;
    
  S3mD = rbinom(S3, 1-dt*mu); // S3 minus Death: mu is the death rate, so it's 1-mu here
  I3mD = rbinom(I3, 1-dt*mu);
  R3mD = rbinom(R3, 1-dt*mu);
    
  prob_S3[0] = 1-exp(-dt*beta3*kappa*I/N);
  prob_S3[1] = exp(-dt*beta3*kappa*I/N);
    
  prob_I3[0] = 1 - exp(-dt*gamma);
  prob_I3[1] = exp(-dt*gamma);
    
  prob_R3[0] = 1 - exp(-dt*omega);
  prob_R3[1] = exp(-dt*omega);
    
  // Transition
  // B: S->I
  // C: I->R
  // F: Aging: (1)->(2)->(3)
  // E: R->S
  // D: Death
  //// Note: Here S_1, S_2... are all old values from (t-1)
  rmultinom(S1, &prob_S1, 3, &trans_S1); // B, F, S-B-F
  rmultinom(I1, &prob_I1, 3, &trans_I1); // C, F, I-C-F
  rmultinom(R1, &prob_R1, 3, &trans_R1); // E, F, R-E-F
    
  rmultinom(S2, &prob_S2, 3, &trans_S2); // B, F, S-B-F
  rmultinom(I2, &prob_I2, 3, &trans_I2); // C, F, I-C-F
  rmultinom(R2, &prob_R2, 3, &trans_R2); // E, F, R-E-F
    
  rmultinom(S3mD, &prob_S3, 2, &trans_S3); // B, (S-D)-B
  rmultinom(I3mD, &prob_I3, 2, &trans_I3); // C, (I-D)-C
  rmultinom(R3mD, &prob_R3, 2, &trans_R3); // E, (R-D)-E
    
  S1 = trans_S1[2] + trans_R1[0] + rpois(4*1025.7); // Include Birth
  I1 = trans_I1[2] + trans_S1[0];
  R1 = trans_R1[2] + trans_I1[0];
    
  S2 = trans_S2[2] + trans_R2[0] + trans_S1[1]; // Include Aging
  I2 = trans_I2[2] + trans_S2[0] + trans_I1[1];
  R2 = trans_R2[2] + trans_I2[0] + trans_R1[1];
    
  S3 = trans_S3[1] + trans_R3[0] + trans_S2[1]; // Include Aging
  I3 = trans_I3[1] + trans_S3[0] + trans_I2[1];
  R3 = trans_R3[1] + trans_I3[0] + trans_R2[1];
    
  //Accumvar
  H1 += trans_S1[0];
  H2 += trans_S2[0];
  H3 += trans_S3[0];
    
  q1 = -1; 
  while(q1 < 0 || q1 > 1){
    q1 = rnorm(0.07, sigma_q);
  }
    
  q2 = -1; 
  while(q2 < 0 || q2 > 1){
    q2 = rnorm(0.07, sigma_q);
  }
    
  q3 = -1; 
  while(q3 < 0 || q3 > 1){
    q3 = rnorm(0.07, sigma_q);
  }
")


# full-estimate-rinit
rinit_full <- Csnippet("
  double m = N/(S10+I10+R10+S20+I20+R20+S30+I30+R30);
  I1=nearbyint(m*I10);
  I2=nearbyint(m*I20);
  I3=nearbyint(m*I30);
  S1=nearbyint(m*S10);
  S2=nearbyint(m*S20);
  S3=nearbyint(m*S30);
  R1=nearbyint(m*R10);
  R2=nearbyint(m*R20);
  R3=nearbyint(m*R30);
  H1 = 0;
  H2 = 0;
  H3 = 0;
")

# WWR's rinit
rinit_wwr <- Csnippet("
  S1=3876549;
  S2=57139612;
  S3=19573727;
  I1=30351;
  I2=871;
  I3=2550;
  R1=1315221;
  R2=302852;
  R3=131092;
  H1 = 0;
  H2 = 0;
  H3 = 0;
")

# x <- c(3876549,57139612,19573727,30351,871,2550,1315221,302852,131092)
# x/sum(x)

# define parameters (fixed)
params_fixed <- c(
  gamma = 1, 
  delta1 = 1/(5*52),
  delta2 = 1/(55*52), 
  alpha = 1/(78.86912*52), 
  mu = 0, 
  N = 82372825, 
  omega = 1/(1*52)
)
# Set to MLE
params_wwr <- c(
  params_fixed, 
  "beta1" = 11.48,
  "beta2" = 0.25,
  "beta3" = 0.35,
  "phi" = 0.14,
  "beta11" = 0.16,
  "sigma_q" = 0.021,
  "sigma_xi" = 66.89
)

params_full <- c(
  params_wwr,
  "S10" = 4.706102e-02,
  "S20" = 6.936707e-01,
  "S30" = 2.376236e-01,
  "I10" = 3.684589e-04,
  "I20" = 1.057388e-05,
  "I30" = 3.095681e-05,
  "R10" = 1.596669e-02,
  "R20" = 3.676601e-03,
  "R30" = 1.591447e-03
)

pt_full <- pomp::parameter_trans(
  log = c("beta1", "beta2", "beta3", "sigma_q", "sigma_xi"),
  logit = c("beta11"),
  barycentric = c("S10","I10","R10",
                  "S20","I20","R20",
                  "S30","I30","R30"),
  toEst = pomp::Csnippet("T_phi = logit(phi/(M_2PI));"),
  fromEst = pomp::Csnippet("phi = M_2PI*expit(T_phi);")
)

pt_wwr <- pomp::parameter_trans(
  log = c("beta1", "beta2", "beta3", "sigma_q", "sigma_xi"),
  logit = c("beta11"),
  toEst = pomp::Csnippet("T_phi = logit(phi/(M_2PI));"),
  fromEst = pomp::Csnippet("phi = M_2PI*expit(T_phi);")
)


dat <- read.table("real_rotavirus_metadata.txt") |>
  arrange(time)

statenames <- c(
  "S1", "I1", "R1", "H1",
  "S2", "I2", "R2", "H2",
  "S3", "I3", "R3", "H3",
  "q1", "q2", "q3"
)

sir_wwr <- pomp(
  data = dat,
  times = "time",
  t0 = 0,
  dmeasure = dmeas,
  rmeasure = rmeas,
  rprocess = discrete_time(step.fun = rproc, delta.t = 1/4),
  statenames = statenames,
  paramnames = names(params_wwr),
  accumvars = c("H1", "H2", "H3"),
  rinit = rinit_wwr,
  partrans = pt_wwr,
  params = params_wwr
) 

sir_full <- pomp(
  sir_wwr,
  rinit = rinit_full,
  params = params_full,
  partrans = pt_full,
  statenames = statenames,
  paramnames = names(params_full)
)
@


% Maximization Round 1

<<maximization1, echo=F, warning=F, message=F>>=
set.seed(123)
sir_box <- list(
  beta1 = c(10, 15),
  beta2 = c(0.2, 0.4),
  beta3 = c(0.3, 0.5),
  phi = c(0.01, 0.3),
  beta11 = c(0.1, 0.2),
  sigma_q = c(0.001, 0.1),
  sigma_xi = c(65, 70),
  S10 = c(0.01, 0.05),
  I10 = c(0.0001, 0.0005),
  R10 = c(0.01, 0.05),
  S20 = c(0.01, 0.7),
  I20 = c(0.000001, 0.00002),
  R20 = c(0.001, 0.005),
  S30 = c(0.01, 0.5),
  I30 = c(0.000001, 0.0001),
  R30 = c(0.0001, 0.005),
  gamma = c(1, 1),
  delta1 = c(1/(5*52), 1/(5*52)),
  delta2 = c(1/(55*52), 1/(55*52)),
  alpha = c(1/(78.86912*52), 1/(78.86912*52)),
  mu = c(0, 0),
  N = c(82372825, 82372825),
  omega = c(1/(1*52), 1/(1*52))
)

design_matrix <- runif_design(
  lower = sapply(sir_box, `[`, 1),
  upper = sapply(sir_box, `[`, 2),
  n = ncores
)

bake(file = paste0(out_dir, "mif2_maximization/round_01/mifs_global_01.rds"),{ 
  plan(multicore, workers = ncores)
  foreach(i = 1:ncores, .options.future = list(seed = 652643293)) %dofuture% {
    pomp::mif2(
      sir_full,
      Np = NP_MIF,
      cooling.fraction.50 = 0.5,
      rw.sd = rw_sd(
        beta1 = 0.01, beta2 = 0.01, beta3 = 0.01, beta11 = 0.01, 
        phi = 0.01, sigma_q = 0.01, sigma_xi = 0.01,
        S10 = ivp(0.24), I10 = ivp(0.24), R10 = ivp(0.24),
        S20 = ivp(0.24), I20 = ivp(0.24), R20 = ivp(0.24),
        S30 = ivp(0.24), I30 = ivp(0.24), R30 = ivp(0.24)
      ),
      cooling.type = "geometric",
      Nmif = NMIF,
      params = design_matrix[i, ]
    ) 
  }
}) -> mifs_global_01 


bake(file = paste0(out_dir, "mif2_maximization/round_01/el_01.rds"),{
  eval_logLik_pomp(mifs_global_01, ncores, NP_MIF, 4248930)
}) ->  el_01

@


% Continue: Maximization Round 2

<<maximization2, echo=F, warning=F, message=F>>=
set.seed(1234)
sd_02 = 2/3
starting_values_02 <- choose_n_fits(el_01, top_n_fits, ncores)

bake(file = paste0(out_dir,"mif2_maximization/round_02/mifs_global_02.rds"),{ 
  plan(multicore, workers = ncores)
  foreach(i = 1:ncores, .options.future = list(seed = 652643293)) %dofuture% {
    pomp::mif2(
      mifs_global_01[[1]],
      rw.sd = rw_sd(
        beta1 = 0.01*sd_02, beta2 = 0.01*sd_02, beta3 = 0.01*sd_02,
        beta11 = 0.01*sd_02, phi = 0.01*sd_02,
        sigma_q = 0.01*sd_02, sigma_xi = 0.01*sd_02,
        S10 = ivp(0.24)*sd_02, I10 = ivp(0.24)*sd_02, R10 = ivp(0.24)*sd_02,
        S20 = ivp(0.24)*sd_02, I20 = ivp(0.24)*sd_02, R20 = ivp(0.24)*sd_02,
        S30 = ivp(0.24)*sd_02, I30 = ivp(0.24)*sd_02, R30 = ivp(0.24)*sd_02
      ),
      params = starting_values_02[[i]]
    ) 
  }
}) ->  mifs_global_02


bake(file = paste0(out_dir, "mif2_maximization/round_02/el_02.rds"),{
  eval_logLik_pomp(mifs_global_02, ncores, NP_MIF, seed=4248930)
}) ->  el_02
@

% Continue: Maximization Round 3

<<maximization3, echo=F, warning=F, message=F>>=
set.seed(12345)
sd_03 = (2/3)^2
starting_values_03 <- choose_n_fits(el_02, top_n_fits, ncores)

bake(file = paste0(out_dir, "mif2_maximization/round_03/mifs_global_03.rds"),{ 
  plan(multicore, workers = ncores)
  foreach(i = 1:ncores, .options.future = list(seed = 652643293)) %dofuture% {
    pomp::mif2(
      mifs_global_02[[1]],
      rw.sd = rw_sd(
        beta1 = 0.01*sd_03, beta2 = 0.01*sd_03, beta3 = 0.01*sd_03,
        beta11 = 0.01*sd_03, phi = 0.01*sd_03,
        sigma_q = 0.01*sd_03, sigma_xi = 0.01*sd_03,
        S10 = ivp(0.24)*sd_03, I10 = ivp(0.24)*sd_03, R10 = ivp(0.24)*sd_03,
        S20 = ivp(0.24)*sd_03, I20 = ivp(0.24)*sd_03, R20 = ivp(0.24)*sd_03,
        S30 = ivp(0.24)*sd_03, I30 = ivp(0.24)*sd_03, R30 = ivp(0.24)*sd_03
      ),
      params = starting_values_03[[i]]
    ) 
  }
}) -> mifs_global_03


bake(file = paste0(out_dir,"mif2_maximization/round_03/el_03.rds"),{
  eval_logLik_pomp(mifs_global_03, ncores, NP_MIF, seed = 4248930)
}) ->  el_03
@


<<estimated-mle, echo=FALSE, message=FALSE, warning=FALSE>>=
# Can be changed if more rounds needed
est_mle_vec <- el_03[which.max(el_03$logLik),]
@

%%%%%%%%%% 11111111 %%%%%%%%%%%%

\section{Introduction}

This article results from an investigation of the results presented by \citet{wwr} (henceforth, WWR) in their Table~1.
WWR were given the opportunity to submit a correction, after we shared the results of our investigation with them, but they declined.
The theory developed by \cite{wwr} shows that PAL has some potentially useful scaling properties, but the numerical results in Table~1 appear to show much stronger performance than a standard particle filter on an example of scientific interest but moderate size.
Our task here is to correct the error in Table~1 so that researchers considering whether to implement Poisson approximate likelihood (PAL) are appropriately informed about its benefits.

Table~1 of WWR reanalyzes the model and data of \citet{stocks} (henceforth, SBH) for which the likelihood was calculated using a particle filter.
SBH found strong evidence for the importance of overdispersion in a stochastic dynamic model for their epidemiological data.
This is significant because earlier research on population dynamics largely avoided consideration of overdispersion, perhaps because of the lack of statistical methodology to fit such models. 
The conclusions of SBH hinge on a comparison of likelihoods, and so the results of WWR discredit those conclusions by indicating that SBH used an inaccurate filter to calculate their likelihoods.
An important consequence of correcting Table~1 is that the results of SBH stand undiminished. 

SBH and WWR each fitted three different rotavirus models.
The first has equidispersion (i.e., no overdispersion) in the measurement model and the dynamic model, and is called
EqEq.
The second, EqOv, includes overdispersion in only the measurement model.
The third, OvOv, includes overdispersion in both these model components.
We focus on OvOv, which both SBH and WWR find to be the best fitting model. 
However, WWR report in Table~1 that their EqOv model fits better than the SBH OvOv model, from which one might conclude that the use of PAL is more important than the decision of whether to include overdispersion in the process model.

We show that most of the apparent advantage for PAL, compared to a particle filter, arises because \cite{wwr} used a different scaling of the data from \cite{stocks}.
Two models for the same data can properly be compared by their likelihood, even if the models have entirely different structures.
One can make allowance for the number of estimated parameters using a quantity such as Akaike's information criterion \citep{Akaike1974ANL}.
However, if data are rescaled, a correction is required to make likelihoods comparable.
For example, if one model describes a dataset in grams and another describes it in kilograms, then the latter model will earn an increased log-likelihood of $\log(10^3)$ for each data point simply because of the change in scale.
Presenting a direct comparison of a likelihood for the data in grams with a likelihood for the data in kilograms would evidently be inappropriate.

\cite{stocks} fitted their model to a dataset derived by dividing the original reported count data by an estimated reporting rate, to put their data on the scale of the actual number of cases in the population, whereas \cite{wwr} fitted directly to the report data.
The reporting rate used by \cite{stocks} varied over time, but was generally around $7\%$.
On approximately 1200 data points, this corresponds to a discrepancy of around $-1200\log(0.07) \approx 3200$ log-likelihood units, largely explaining the difference reported in Table~1 and interpreted by \cite{wwr} as evidence supporting PAL.
The comparison can be corrected either by applying the method of SBH to the data of WWR or vice versa.
Since the method of SBH is applicable to a more general class of models, and supported by published software, it was convenient to apply the SBH method to the model and data of WWR.
The large discrepancy in log-likelihood disappears at this point by recomputing the likelihood of the model using PAL and particle filter separately (see Table~\ref{tab:ovovrealdata}).
This re-analysis does, however, show a discrepancy between two methods.
We continued our investigation to establish the cause of this.
We discovered that the initial conditions for the latent process in January 2001 (their time 0) were estimated by SBH. However, in WWR, they were assumed fixed and made the model fitted poorly. 

<<sim-100, echo=F, warning=F, message=F>>=
bake(file = paste0(out_dir, "pfilter/simulated_dataset/ovov_sim_100.rds"),{
  ovov_sim_computation <- list()
  
  i <- 1
  repeat {
    # Simulation
    sim_data <- simulate(sir_wwr, format = "data.frame") |>
      subset(select=c("time", "cases1", "cases2", "cases3"))
    
    if (!any(sim_data == 0)) {
      ovov_sim_computation[[length(ovov_sim_computation) + 1]] <- sim_data
      i <- i + 1  
    } else {
      print(paste("Condition not met for iteration", i, "- retrying"))
    }
    
    if (length(ovov_sim_computation) >= sim_rep) break  
  }
  ovov_sim_computation
}) -> ovov_sim_100
@


<<pfilter_sim_100, echo=FALSE, message=FALSE, warning=FALSE, results='hide'>>=
bake(file = paste0(out_dir, "pfilter/simulated_dataset/pfilter_ovov_sim_100.rds"),{
  pfilter_obj <- list()
  pfilter_ovov_sim_computation <- c()
  
  for(i in 1:length(ovov_sim_100)){
    pomp(
      data = ovov_sim_100[[i]],
      times = "time",
      t0 = 0,
      dmeasure = dmeas,
      rmeasure = rmeas,
      rprocess = discrete_time(step.fun = rproc, delta.t = 1/4),
      statenames = statenames,
      paramnames = names(params_wwr),
      accumvars = c("H1", "H2", "H3"),
      rinit = rinit_wwr,
      partrans = pt_wwr,
      params = params_wwr
    )  -> pfilter_obj[[i]]
    
    plan(multicore, workers = ncores)
    
    foreach(j = 1:ncores, .combine = c,
      .options.future = list(seed = 998468235L)
    ) %dofuture% {
      pfilter(
        pfilter_obj[[i]], Np = NP_MIF, save.states = FALSE, params = params_wwr
      )
    } -> pfs
    pfilter_ovov_sim_computation[i] <- logmeanexp(logLik(pfs))  
  }
  pfilter_ovov_sim_computation
}) ->  pfilter_ovov_sim_100
@



<<palfilter_sim_100, echo=FALSE, message=FALSE, warning=FALSE, results='hide'>>=
prop <- 420
init_dist <- c(
  3876549, 30351, 1315221, 57139612, 871, 302852, 19573727, 2550, 131092
)
initial_guess <- c(11.48, 0.25, 0.35, 0.14, 0.16, 0.021, 66.89)

bake(file = paste0(out_dir, "pfilter/simulated_dataset/palfilter_ovov_sim_100.rds"),{
  plan(multicore, workers = ncores)
  foreach(
    i = 1:length(ovov_sim_100), .combine = c, .options.future = list(seed = 998468235L)
  ) %dofuture% {
    pal_sim_dat <- ovov_sim_100[[i]][,-1] |> as.matrix()
    lik_list <- rotavirus_SMC_qropxi(
      init_dist = init_dist, 
      y_obs = pal_sim_dat, 
      m = 9, 
      regular_params = c(
        initial_guess[1], initial_guess[2], initial_guess[3], initial_guess[4],
        initial_guess[5]
      ), 
      gamma_par = c(initial_guess[7], 1/initial_guess[7]), 
      norm_par = c(0.07, initial_guess[6]), 
      prop = t(prop), 
      n_particles = NP_MIF,
      ncores = ncores
    )
    lik_list$log_lik
  }
}) -> palfilter_ovov_sim_100

# lik_list$ll_storage |> sum()
@

<<plot1-100-sim-compare,echo=FALSE, fig.height=4, fig.width=5.5, fig.cap='Log-likelihoods computed using two filtering methods for 100 randomly simulated datasets at the MLE of the OvOv model. The particle filter and PAL used 50,000 particles. The red line corresponds to equality of the two estimates. On average, the particle filter likelihood estimate is $7.7$ log units higher than the PAL.'>>=
data <- data.frame(
  pfilter = pfilter_ovov_sim_100, 
  palfilter = palfilter_ovov_sim_100
)

ggplot(data, aes(x = pfilter, y = palfilter)) +
geom_point(shape = 20, size = 0.3) +  # pch=20, cex=0.3 equivalent
geom_abline(intercept = 0, slope = 1, color = "red") +
labs(
title = "PAL vs SMC: OvOv with 100 simulations",
x = "pfilter",
y = "palfilter"
) +
theme_minimal()
@


<<pfilter_wwr, echo=FALSE, message=FALSE, warning=FALSE>>=
bake(file = paste0(out_dir, "pfilter/original_dataset/pfilter_wwr.rds"),{
  plan(multicore, workers = ncores)
  foreach(
    i = 1:ncores, .combine = c, .options.future = list(seed = 998468235L)
  ) %dofuture% {
      pfilter(sir_wwr, Np = NP_MIF, params = params_wwr)
    } 
}) ->  pfilter_wwr

bake(file = paste0(out_dir, "pfilter/original_dataset/pfilter_wwr_cond_lik.rds"),{
  pfilter_wwr_cond_lik_computation <- list()
  for(k in 1:ncores){
    pfilter_wwr_cond_lik_computation[[k]] <- pfilter_wwr[[k]]@cond.logLik
  }
  pfilter_wwr_cond_lik_computation
}) -> pfilter_wwr_cond_lik
@

<<palfilter_wwr, echo=FALSE>>=
realdat <- as.matrix(dat[,-1])

bake(file = paste0(out_dir,"pfilter/original_dataset/palfilter_lik_list_wwr.rds"),{
 set.seed(1223)
 rotavirus_SMC_qropxi(
    init_dist = init_dist, 
    y_obs = realdat, 
    m = 9, 
    regular_params = c(
      initial_guess[1], initial_guess[2], initial_guess[3], initial_guess[4],
      initial_guess[5]
    ), 
    gamma_par = c(initial_guess[7], 1/initial_guess[7]), 
    norm_par = c(0.07, initial_guess[6]), 
    prop = t(prop), 
    n_particles = NP_MIF, 
    ncores = ncores
  ) 
}) -> palfilter_lik_list_wwr
@

\begin{table}[ht] % The placement specifier can be [h!tbp]
\centering % Centers the table
\caption{log-likelihood at the MLE of OvOv model for the real rotavirus data, computed using two filtering methods, employed 36 replicates and 50,000 particles} 
\label{tab:ovovrealdata} % For referencing this table elsewhere in your text
\begin{tabular}{|c c c|} 
 \hline
  & PAL & SMC  \\
  \hline
 OvOv & \Sexpr{round(palfilter_lik_list_wwr$log_lik,2)} & $\Sexpr{round(logmeanexp(logLik(pfilter_wwr),2))}$ \\ 
 \hline
\end{tabular}
\end{table}

<<plot2-cond-loglik, echo=FALSE, fig.height=4, fig.width=5.5, fig.cap='Conditional log-likelihoods computed using two methods for the real rotavirus dataset, with the SMC method replicated 36 times due to its high variances. The blue line represents overlapping results from 36 SMC computations, while the red line is derived from PAL. The main sources of likelihood shortfall of SMC are at time points $t=1, 2, 3, 11, 81, 194$, and $325-333$.'>>=

# Combine the data into a single dataframe for SMC with grouping variable
data_list <- lapply(1:ncores, function(i) {
  data.frame(
    time = time, 
    cond_loglik = pfilter_wwr_cond_lik[[i]], 
    method = "SMC",
    group = i
  )
})

# Combine all the SMC data frames into one
df_smc <- bind_rows(data_list)

# Create the PAL data frame
df_pal <- data.frame(
  time = time, 
  cond_loglik = palfilter_lik_list_wwr$ll_storage, 
  method = "PAL",
  group = 1  # Single group for PAL
)

# Combine both data frames
df <- bind_rows(df_smc, df_pal)

# Plot with ggplot
ggplot(df, aes(x = time, y = cond_loglik, color = method)) +
  geom_line(data = df %>% filter(method == "SMC"), aes(group = group), color = "blue", alpha = 0.7) +
  geom_line(data = df %>% filter(method == "PAL"), aes(group = group), color = "red") +
  theme_minimal() +
  labs(
    title = "Conditional Log Likelihood Over Time",
    x = "Time",
    y = "Conditional Log Likelihood",
    color = "Method"
  ) +
  theme(legend.position = "bottom")
@



Figure~2 indicates that the worst conditional log-likelihood values, estimated using the particle filter, arise at the start of the time series.
This could be a problem with data collection, or some subtle issue with the science of the epidemiological system, but a simple possibility is that the initial values of the latent state process might be poorly specified.
For this model, the initial values were fixed based on scientific reasoning, rather than being estimated.
If we instead estimate the initial values, we obtain the results in Table~\ref{tab:mlebywwr}. 

\begin{table}[htbp]
    \caption{Maximum likelihood estimation of parameters by PAL \citep{wwr}, and by mif2 algorithm \citep{pomppackagepaper} for the OvOv model. The initial distribution parameter \(\lambda_0 = (S_{10}, I_{10}, R_{10}, S_{20}, I_{20}, R_{20}, S_{30}, I_{30}, R_{30})\) are assumed to be \textbf{fixed} in \cite{wwr}. The iterated filtering estimates were obtained by using 3 rounds of refinement, with 100 filtering iterations, 50,000 particles, and 36 replicates in each round with the top 12 best fits in terms of likelihood chosen to be the starting value for the next round.}
    \label{tab:mlebywwr}
\begin{center}    
    \begin{tabular}{lcc}  % Left-aligned for the first column, centered for the other two columns
      \toprule
      Parameter      & PAL      & iterated filtering \\
      \midrule
      \(\beta_1\)    & 11.48     & $\Sexpr{round(est_mle_vec["beta1"],2)}$\\
      \(\beta_2\)    & 0.25      & $\Sexpr{round(est_mle_vec["beta2"],2)}$\\
      \(\beta_3\)    & 0.35      & $\Sexpr{round(est_mle_vec["beta3"],2)}$\\
      \(\phi\)       & 0.14      & $\Sexpr{round(est_mle_vec["phi"],2)}$\\
      \(\rho\)       & 0.16      & $\Sexpr{round(est_mle_vec["beta11"],2)}$\\
      \(\sigma^2_q\) & 0.021     & $\Sexpr{round(est_mle_vec["sigma_q"],3)}$\\
      \(\sigma_\xi\) & 66.89     & $\Sexpr{round(est_mle_vec["sigma_xi"],2)}$\\
      \(S_{10}\)     & 3876549   & $\Sexpr{round(pop*est_mle_vec["S10"],0)}$\\
      \(I_{10}\)     & 30351     & $\Sexpr{round(pop*est_mle_vec["I10"],0)}$\\
      \(R_{10}\)     & 1315221   & $\Sexpr{round(pop*est_mle_vec["R10"],0)}$\\
      \(S_{20}\)     & 57139612  & $\Sexpr{round(pop*est_mle_vec["S20"],0)}$\\
      \(I_{20}\)     & 871       & $\Sexpr{round(pop*est_mle_vec["I20"],0)}$\\
      \(R_{20}\)     & 302852    & $\Sexpr{round(pop*est_mle_vec["R20"],0)}$\\
      \(S_{30}\)     & 19573727  & $\Sexpr{round(pop*est_mle_vec["S30"],0)}$\\
      \(I_{30}\)     & 2550      & $\Sexpr{round(pop*est_mle_vec["I30"],0)}$\\
      \(R_{30}\)     & 131092    & $\Sexpr{round(pop*est_mle_vec["R30"],0)}$\\
      \midrule
      \textbf{AIC}  & 13778.08  & $\Sexpr{round(2*((length(params_wwr) - length(params_fixed)) - est_mle_vec["logLik"]),2)}$\\
      \bottomrule
    \end{tabular}
\end{center}
\end{table}

\section*{Discussion}

PAL provides an approximate filter, whereas the particle filter provides a Monte~Carlo estimate of an exact filter.
Possible explanations for PAL obtaining a higher log-likelihood than a particle filter include:
\begin{enumerate}
\item The particle filter could have high Monte Carlo variance. This results in negative bias in its log-likilihood estimate due to Jensen's inequality, since the particle filter provides an unbiased likelihood estimate.
\item If the model is misspecified, the approximation error in PAL could lead to a higher log-likelihood estimate than that of the actual misspecified model.
\end{enumerate}
Log-likelihood is a proper scoring rule for forecasts \cite{gneiting2}, and both the particle filter and PAL construct their log-likelihood estimates via a sequence of one-step forecasts.
Therefore, if the model is correctly specified, the approximation error in PAL can only decrease the expected log-likelihood.
We tested this on simulated data, for which the model of \cite{wwr} is correctly specified.
We focus on the version of the model with overdispersion in both the population dynamics and the measurement process.
This version of the model, called OvOv, was found by both \cite{wwr} and \cite{stocks} to be the best choice to fit the data.
For this simulation study, the particle filter out-performs PAL (Figure~1) which supports hypothesis 2, above.
Consequently, we looked for model misspecification by comparing the conditional log-likelihood estimates at each time point, as described in the Methods section.

We conclude that PAL is a potentially useful algorithm, with some favorable theoretical properties.
However, the corrected evidence does not indicate an advantage for using PAL in situations where the particle filter is effective.

%%%%%%%%% 222222222 %%%%%%%%%%

\section*{Methods}

\yize{ON AVERAGE PAL IS 25.3 LOG UNITS LOWER THAN PFILTER AND SHOULD WE MENTION THAT WE USED THE SIMULATED DATA WITHOUT ZEROS?}

We first replicated the model of \citet{wwr} in the R package \textbf{pomp} \citep{pomppackagepaper}.
Comparing summary statistics of simulations confirms that both model versions are essentially identical, as described by \citet{hao24}.
We therefore implement PAL using the code from \citet{wwr}, comparing directly with the particle filter implemented using \textbf{pomp}.

This article has focused on likelihood evaluation, but the inferences presented also require the likelihood estimate to be maximized.
\cite{wwr} used direct numerical maximization, whereas \cite{stocks} used iterated filtering to maximize the particle filter likelihood estimate implemented using the \texttt{mif2} algorithm in \textbf{pomp}.
We follow the approaches adopted by these two papers.
The optimization method is not directly pertinent to the comparison of the filtering methods, so we do not discuss optimization in further detail here.
An extended description of our reanalysis of \cite{wwr} is provided by \cite{hao24}.
That thesis also contains some additional results reinforcing the conclusions presented in this article.
The source code for this article is available at \url{https://github.com:ionides/pal-vs-pf} and archived at \ed{ZENODO - TODO}.

\bibliography{bib-pal}

\end{document}
